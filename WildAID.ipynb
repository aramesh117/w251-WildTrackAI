{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WildAID.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PM6fb0vDbhAa"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jtdsouza/w251-WIldTrackAI/blob/master/WildAID.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA2Q3Tn6YPbN",
        "colab_type": "text"
      },
      "source": [
        "# Initialization and Load Image Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVEyGQQmufJu",
        "colab_type": "code",
        "outputId": "402c72eb-a1fe-4e01-d2c6-a350b2e19822",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Set up Tensor flow 2.0\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u-mWgHlgum4P",
        "outputId": "5e909de9-eff6-40a6-d038-a994756b320e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D, BatchNormalization, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.layers import Lambda, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import he_normal\n",
        "from tensorflow.keras.initializers import lecun_normal\n",
        "from tensorflow.keras.initializers import he_uniform\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.initializers import glorot_normal\n",
        "from tensorflow.keras import backend as K\n",
        "from keras.preprocessing import image as KImage\n",
        "\n",
        "import cv2\n",
        "import csv\n",
        "import os\n",
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "import pandas as pd\n",
        "from google.colab.patches import cv2_imshow\n",
        "from collections import defaultdict\n",
        "import random\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input as VGG16Pre\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input as VGG19Pre\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input as InceptionPre\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.applications.xception import preprocess_input as XceptionPre\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as MNPre\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
        "from tensorflow.keras.applications.nasnet import NASNetMobile\n",
        "from tensorflow.keras.applications.densenet import DenseNet121\n",
        "\n",
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import pickle\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOq_0bZOKqT8",
        "colab_type": "code",
        "outputId": "573867b4-e4df-48a4-bbb5-810444cccfd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#Mount Google Drive - Note this mounts your personal GDrive to the directory stated\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJpw6HR34887",
        "colab_type": "text"
      },
      "source": [
        "## Load Images and setup Data Structures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKqL-xdT9jcp",
        "colab_type": "text"
      },
      "source": [
        "Images are loaded from csv files that contain previously processed data sets.\n",
        "The preprocessing implementation can be found here: https://colab.research.google.com/drive/1tVg9y71wbf_-bpgOue4LAFbCSXuu2SCD?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39LcbZgrd4Pn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  #Set up path for csv files containing preprocessed images. Need to map U C Berkeley - Darragh/ shared to your personal GDrive for this to work. \n",
        "  csvpath='/content/drive/My Drive/U C Berkeley - Darragh/csv'\n",
        "\n",
        "  #Function to load processed image data in csv files (both training and test, input data labels)\n",
        "  def LoadData(train_imagefile=\"Training-Images-224.csv\",train_labelfile=\"Training-Labels-224.txt\",\n",
        "               test_imagefile=\"Test-Images-224.csv\",test_labelfile=\"Test-Labels-224.txt\"):\n",
        "    \n",
        "    #Training Data Set\n",
        "    X=[]\n",
        "    Individuals=[]\n",
        "    Species=[]\n",
        "    Ind_DB=defaultdict(defaultdict)\n",
        "\n",
        "    \n",
        "    dataset=np.loadtxt(os.path.join(csvpath,train_imagefile),delimiter=\",\")\n",
        "    f=open(os.path.join(csvpath,train_labelfile),'r')\n",
        "    lines=f.readlines()\n",
        "    for line in lines:\n",
        "      vals=line.rstrip()\n",
        "      Species.append(vals.split(\"-\")[0])\n",
        "      Individuals.append(vals)\n",
        "    i=0\n",
        "    for x in dataset:\n",
        "      image=x.reshape(224,224,3)\n",
        "      X.append(image)\n",
        "      species=Species[i]\n",
        "      key=Individuals[i]\n",
        "      spec_DB=Ind_DB[species]\n",
        "      if key not in spec_DB.keys():\n",
        "        spec_DB[key]=[image]\n",
        "      else:\n",
        "        spec_DB[key].append(image)\n",
        "      i=i+1\n",
        "\n",
        "\n",
        "    #Test Data Set\n",
        "    X_Test=[]\n",
        "    Individuals_Test=[]\n",
        "    Species_Test=[]\n",
        "    dataset=np.loadtxt(os.path.join(csvpath,test_imagefile),delimiter=\",\")\n",
        "\n",
        "    for x in dataset:\n",
        "      image=x.reshape(224,224,3)\n",
        "      X_Test.append(image)\n",
        "\n",
        "    f=open(os.path.join(csvpath,test_labelfile),'r')\n",
        "    lines=f.readlines()\n",
        "    for line in lines:\n",
        "      vals=line.rstrip()\n",
        "      Species_Test.append(vals.split(\"-\")[0])\n",
        "      Individuals_Test.append(vals)\n",
        "\n",
        "    X_Test=np.asarray(X_Test)\n",
        "    X=np.asarray(X)\n",
        "    return (X,Species,Individuals,Ind_DB,X_Test,Species_Test,Individuals_Test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja697BTjQnXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Pre-Processed Images\n",
        "\n",
        "X,Species,Individuals, Ind_DB,X_Test,Species_Test,Individuals_Test=LoadData()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aan_gNm77C3w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "99d648bf-fc0b-4315-fc7c-6f289278b81e"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "le = LabelEncoder()\n",
        "le.fit(Species)\n",
        "Y=le.transform(Species)\n",
        "Y_Test=le.transform(Species_Test)\n",
        "Y1=to_categorical(np.array(Y))\n",
        "Y_Test1=to_categorical(np.array(Y_Test))\n",
        "print(Y1.shape)\n",
        "print(le.classes_)\n",
        "#For Species Classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_Train, X_Val, Y_Train, Y_Val = train_test_split(X, Y1, test_size=0.10, random_state=42)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1437, 8)\n",
            "['Amur Tiger' 'Bengal Tiger' 'Black Rhino' 'Cheetah' 'Leopard'\n",
            " 'Lowland Tapir' 'Puma' 'White Rhino']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-vnCtF1YyBQ",
        "colab_type": "text"
      },
      "source": [
        "# VGG16 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffwUK27S-T7p",
        "colab_type": "text"
      },
      "source": [
        "Reference implementation for both Species Classification and Individual Identification done with VGG16 pretrained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPPotfxT4UKa",
        "colab_type": "text"
      },
      "source": [
        "## Load/Setup Base Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjpNgt5baHX3",
        "colab_type": "code",
        "outputId": "5261a949-1f93-4c1b-b49e-2de2997fa098",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "input_shape=(224,224,3)\n",
        "vgg=VGG16(weights='imagenet',include_top=False,input_shape=input_shape)\n",
        "vgg.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 5s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3Q0ZB8gnEPf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "aee0f25a-c582-4024-e733-5494e793b643"
      },
      "source": [
        "vgg=VGG16(weights='imagenet',include_top=False,input_shape=input_shape)\n",
        "vgg.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vr_J_LbTYaQm",
        "colab_type": "text"
      },
      "source": [
        "## Species Classification Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyWuU_oDZHWn",
        "colab_type": "text"
      },
      "source": [
        "### PreTrained Network - Train all Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhGyQkKXO6Mz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "86038438-df68-45ac-c722-2e3451c620b9"
      },
      "source": [
        "#Set all layers of pretrained VGG16 model as trainable. Add a few dense layers on top\n",
        "\n",
        "vgg_model=Sequential()\n",
        "vgg_model.add(VGG16(weights='imagenet',include_top=False,input_shape=input_shape))\n",
        "vgg_model.add(Flatten())\n",
        "vgg_model.add(Dropout(0.4))\n",
        "vgg_model.add(Dense(256, activation='relu',name=\"Dense1\"))\n",
        "vgg_model.add(Dense(128, activation='relu'))\n",
        "vgg_model.add(Dense(64, activation='relu'))\n",
        "vgg_model.add(Dropout(0.4))\n",
        "vgg_model.add(Dense(8))\n",
        "\n",
        "vgg_model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "Dense1 (Dense)               (None, 256)               6422784   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 520       \n",
            "=================================================================\n",
            "Total params: 21,179,144\n",
            "Trainable params: 21,179,144\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6nsK-Z95qtQ",
        "colab_type": "text"
      },
      "source": [
        "#### First Time training Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxMpxh8vfpxR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "35b039ad-b419-4f73-aac0-3257d9377039"
      },
      "source": [
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "vgg_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.00001),\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])\n",
        "vgg_model.fit(X_Train,Y_Train,validation_data=(X_Val,Y_Val),epochs=30)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1293 samples, validate on 144 samples\n",
            "Epoch 1/30\n",
            "1293/1293 [==============================] - 20s 15ms/sample - loss: 2.9841 - accuracy: 0.1663 - val_loss: 1.9247 - val_accuracy: 0.2500\n",
            "Epoch 2/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 1.9561 - accuracy: 0.2251 - val_loss: 1.6427 - val_accuracy: 0.4861\n",
            "Epoch 3/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 1.6467 - accuracy: 0.3449 - val_loss: 1.2982 - val_accuracy: 0.6042\n",
            "Epoch 4/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 1.4317 - accuracy: 0.4493 - val_loss: 1.0689 - val_accuracy: 0.6806\n",
            "Epoch 5/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 1.2290 - accuracy: 0.5491 - val_loss: 0.8473 - val_accuracy: 0.7222\n",
            "Epoch 6/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 1.0140 - accuracy: 0.6311 - val_loss: 0.7021 - val_accuracy: 0.8125\n",
            "Epoch 7/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 0.8754 - accuracy: 0.6922 - val_loss: 0.5251 - val_accuracy: 0.8681\n",
            "Epoch 8/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 0.6901 - accuracy: 0.7587 - val_loss: 0.4242 - val_accuracy: 0.8958\n",
            "Epoch 9/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 0.6180 - accuracy: 0.7842 - val_loss: 0.4120 - val_accuracy: 0.8681\n",
            "Epoch 10/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 0.5342 - accuracy: 0.8113 - val_loss: 0.2938 - val_accuracy: 0.9167\n",
            "Epoch 11/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 0.4042 - accuracy: 0.8585 - val_loss: 0.3086 - val_accuracy: 0.9028\n",
            "Epoch 12/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 0.3238 - accuracy: 0.8979 - val_loss: 0.1905 - val_accuracy: 0.9375\n",
            "Epoch 13/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 0.3384 - accuracy: 0.8879 - val_loss: 0.1881 - val_accuracy: 0.9306\n",
            "Epoch 14/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 0.2465 - accuracy: 0.9203 - val_loss: 0.1538 - val_accuracy: 0.9444\n",
            "Epoch 15/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 0.1959 - accuracy: 0.9451 - val_loss: 0.1554 - val_accuracy: 0.9583\n",
            "Epoch 16/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 0.1540 - accuracy: 0.9544 - val_loss: 0.1300 - val_accuracy: 0.9583\n",
            "Epoch 17/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 0.1571 - accuracy: 0.9412 - val_loss: 0.3100 - val_accuracy: 0.9028\n",
            "Epoch 18/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 0.1376 - accuracy: 0.9536 - val_loss: 0.1625 - val_accuracy: 0.9306\n",
            "Epoch 19/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 0.1639 - accuracy: 0.9474 - val_loss: 0.0903 - val_accuracy: 0.9514\n",
            "Epoch 20/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 0.0928 - accuracy: 0.9683 - val_loss: 0.1142 - val_accuracy: 0.9583\n",
            "Epoch 21/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 0.1028 - accuracy: 0.9644 - val_loss: 0.1250 - val_accuracy: 0.9722\n",
            "Epoch 22/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 0.0963 - accuracy: 0.9652 - val_loss: 0.1600 - val_accuracy: 0.9444\n",
            "Epoch 23/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 0.1048 - accuracy: 0.9637 - val_loss: 0.1048 - val_accuracy: 0.9583\n",
            "Epoch 24/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 0.0730 - accuracy: 0.9729 - val_loss: 0.1056 - val_accuracy: 0.9583\n",
            "Epoch 25/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 0.0682 - accuracy: 0.9745 - val_loss: 0.0790 - val_accuracy: 0.9792\n",
            "Epoch 26/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 0.0517 - accuracy: 0.9853 - val_loss: 0.1047 - val_accuracy: 0.9583\n",
            "Epoch 27/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 0.0352 - accuracy: 0.9884 - val_loss: 0.1223 - val_accuracy: 0.9653\n",
            "Epoch 28/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 0.0671 - accuracy: 0.9760 - val_loss: 0.1595 - val_accuracy: 0.9583\n",
            "Epoch 29/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 0.0460 - accuracy: 0.9869 - val_loss: 0.0955 - val_accuracy: 0.9722\n",
            "Epoch 30/30\n",
            "1293/1293 [==============================] - 10s 7ms/sample - loss: 0.0674 - accuracy: 0.9729 - val_loss: 0.1198 - val_accuracy: 0.9653\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6dd4964908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE_Jsg91iO2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save model\n",
        "vgg_model.save_weights(os.path.join(csvpath,\"vgg-model.h5\"))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZOIKPCxnwkH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fa9b3eaa-fa52-44ee-a5ec-c256ee16416c"
      },
      "source": [
        "#EVal;uate on Test Data\n",
        "vgg_model.evaluate(X_Test,  Y_Test1, verbose=2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "134/134 - 1s - loss: 0.0926 - accuracy: 0.9701\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.09257133039967295, 0.9701493]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ptUQW0jnyOy",
        "colab_type": "text"
      },
      "source": [
        "#### Subsequent Runs. - Reload model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmWZOXrWnesL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg_model.load_weights(os.path.join(csvpath,\"vgg-model.h5\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW_NprOLqZGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "vgg_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.00001),\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRtD54SVndd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg_model.evaluate(X_Test,  Y_Test1, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xlcrIbVLR5i",
        "colab_type": "text"
      },
      "source": [
        "## Individual Identification Task\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S70fnzJ_6zyy",
        "colab_type": "text"
      },
      "source": [
        "### Common Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8Hu9t6gk01i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Functions used in TRIPLES Network Architecture (for Identification)\n",
        "\n",
        "# Assumes Ind_DB (see load data section) populated with training images, \n",
        "# creates set of triples for training a triplets network using batch size specified below.\n",
        "\n",
        "def GetTriples(batch_size=20,rnd=False):\n",
        "  if rnd:\n",
        "    sample_size=int(batch_size/len(Ind_DB.keys()))\n",
        "  triples=[np.zeros((batch_size,224,224,3))for i in range(3)]\n",
        "  cnt=0\n",
        "  while (cnt<batch_size):\n",
        "    for spec,inds in list(Ind_DB.items()):\n",
        "      names=list(inds.keys())\n",
        "      pop_size=len(names)\n",
        "      if pop_size<2:\n",
        "        continue\n",
        "      else:\n",
        "        if rnd and pop_size>sample_size:\n",
        "          sample=random.sample(names,sample_size)\n",
        "        else:\n",
        "          sample=names\n",
        "\n",
        "      #print(\"Sample: \",sample)\n",
        "\n",
        "      for ind in sample:\n",
        "        nonmatch=\"\"\n",
        "        #print(ind)\n",
        "        key=str(ind)\n",
        "        pair=random.sample(inds[key],2)\n",
        "        triples[0][cnt,:,:,:]=pair[0]\n",
        "        triples[1][cnt,:,:,:]=pair[1]\n",
        "        while len(nonmatch)==0: \n",
        "          x = str(random.sample(names,1)[0])\n",
        "          #print(x)\n",
        "          if x!=key:\n",
        "            nonmatch=x\n",
        "            #print(nonmatch)\n",
        "        triples[2][cnt,:,:,:]=random.sample(inds[nonmatch],1)[0]\n",
        "        cnt=cnt+1\n",
        "        #print(\"Iteration complete: \",cnt)\n",
        "        if cnt==batch_size:\n",
        "          break\n",
        "      if cnt==batch_size:\n",
        "        break\n",
        "  target=np.zeros((batch_size,768))\n",
        "  return triples,target\n",
        "\n",
        "\n",
        "# For use when using keras.modelsfit_generator\n",
        "def batch_gen(batch_size=20,rnd=False):\n",
        "  #print(\"IN!\")\n",
        "  while True:\n",
        "    triples,targets=GetTriples(batch_size,rnd)\n",
        "    x= (triples,targets)\n",
        "    #print(len(triples))\n",
        "    yield (triples,targets)\n",
        "\n",
        "\n",
        "#CUstom loss function for Triplets Network\n",
        "def triplet_loss(y_true,y_pred,alpha=1.0):\n",
        "  ln=y_pred.shape.as_list()[-1]\n",
        "  anchor=y_pred[:,0:int(ln/3)]\n",
        "  positive=y_pred[:,int(ln/3):int(2*ln/3)]\n",
        "  negative=y_pred[:,int(2*ln/3):ln]\n",
        "\n",
        "  p_dist=K.sqrt(K.sum(K.square(anchor-positive),axis=1))\n",
        "  n_dist=K.sqrt(K.sum(K.square(anchor-negative),axis=1))\n",
        "  loss=K.maximum(p_dist-n_dist+alpha,0.0)\n",
        "  return K.mean(loss)  \n",
        "\n",
        "\n",
        "def calcl2(X,prints):\n",
        "  l2norm=[]\n",
        "  for i in range(len(prints)):\n",
        "    l2norm.append(np.linalg.norm(X - prints[i]))\n",
        "  return l2norm\n",
        "\n",
        "def Validate(test_data,master_DB,trained_model):\n",
        "  X=test_data[0]\n",
        "  species=test_data[1]\n",
        "  distary=[]\n",
        "  indary=[]\n",
        "  support_DB=master_DB[species]\n",
        "  for individual,prints in support_DB.items():\n",
        "    prints=np.asarray(prints)\n",
        "    prints_encoded=trained_model.predict(prints)\n",
        "    dist=calcl2(X,prints_encoded)\n",
        "    ind=[individual]*len(dist)\n",
        "    distary.extend(dist)\n",
        "    indary.extend(ind)\n",
        "  order=np.argsort(distary)\n",
        "  #print(distary)\n",
        "  #print(order)\n",
        "  #print(indary)\n",
        "  #print(\"Target Individual: \",true_ind)\n",
        "  #print(distary[i],indary[i])\n",
        "  return indary[order[0]],indary[order[1]],indary[order[2]]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2kpi9gbJAda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use K-Newares Neighbors to evaluate training/ test results\n",
        "\n",
        "def FindKNN(X,Y,X_Test,Y_Test):\n",
        "  k_range=range(1,20)\n",
        "  scores={}\n",
        "  scores_list=[]\n",
        "  for k in k_range:\n",
        "    knn=KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X,Y)\n",
        "    Y_Pred=knn.predict(X_Test)\n",
        "    acc=metrics.accuracy_score(Y_Test,Y_Pred)\n",
        "    scores[k]=acc\n",
        "    scores_list.append(acc)\n",
        "  #print(scores)\n",
        "  return np.argmax(scores_list)\n",
        "\n",
        "\n",
        "def FitKNNs(DB,model):\n",
        "  knns={}\n",
        "  #tsnes={}\n",
        "  for species in DB.keys():\n",
        "    support_DB=DB[species]\n",
        "    X=[]\n",
        "    Y=[]\n",
        "    for individual,prints in support_DB.items():\n",
        "      if 'Unknown' in individual:\n",
        "        continue\n",
        "      else:\n",
        "        prints=np.asarray(prints)\n",
        "        prints_encoded=model.predict(prints)\n",
        "        ind=[individual]*len(prints_encoded)\n",
        "        X.extend(prints_encoded)\n",
        "        Y.extend(ind)\n",
        "    #df=pd.DataFrame(X)\n",
        "    #tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
        "    #tsne_results = tsne.fit_transform(df)\n",
        "    #XT=pd.DataFrame()\n",
        "    #YT=pd.DataFrame(Y)\n",
        "    #XT['tsne-2d-one'] = tsne_results[:,0]\n",
        "    #XT['tsne-2d-two'] = tsne_results[:,1]\n",
        "    X_Train, X_Val, Y_Train, Y_Val = train_test_split(X, Y, test_size=0.20, random_state=42)\n",
        "    #X_Train, X_Val, Y_Train, Y_Val = train_test_split(XT, YT, test_size=0.20, random_state=42)\n",
        "    k=FindKNN(X_Train,Y_Train,X_Val,Y_Val)+1\n",
        "    #print(species,\" : \",k)\n",
        "    #k=3\n",
        "    knn=KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_Train,Y_Train)\n",
        "    knns[species]=knn\n",
        "    #tsnes[species]=tsne\n",
        "  #return knns,tsnes\n",
        "  return knns\n",
        "\n",
        "def predict(knn,x):\n",
        "  #dfx=pd.DataFrame(x)\n",
        "  #tsne_results = tsne.transform(dfx)\n",
        "  #XT=pd.DataFrame()\n",
        "  #XT['tsne-2d-one'] = tsne_results[:,0]\n",
        "  #XT['tsne-2d-two'] = tsne_results[:,1]\n",
        "  predicted=knn.predict(x)\n",
        "  return(predicted)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiR7grte6YRh",
        "colab_type": "text"
      },
      "source": [
        "### Set up Triplets Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICveywr23Jtb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "efa5a9c9-89ce-4da1-9207-820bbbe361d2"
      },
      "source": [
        "#STart with VGG model used for SPecies classification (assumes loaded per previous section)\n",
        "vgg_model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "Dense1 (Dense)               (None, 256)               6422784   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 520       \n",
            "=================================================================\n",
            "Total params: 21,179,144\n",
            "Trainable params: 21,179,144\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxGNZHAQz6Aw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "44b70786-c2d9-4477-e116-03c66a46c779"
      },
      "source": [
        "#Create Triplets Model Network\n",
        "\n",
        "x=vgg_model.get_layer('Dense1').output\n",
        "x = Lambda(lambda  x: K.l2_normalize(x,axis=1))(x)\n",
        "triplet_model=Model(inputs=vgg_model.input,outputs=x)\n",
        "input_shape=[224,224,3]\n",
        "X1=Input(input_shape)\n",
        "X2=Input(input_shape)\n",
        "X3=Input(input_shape)\n",
        "encoded1 = triplet_model(X1)\n",
        "encoded2 = triplet_model(X2)\n",
        "encoded3 = triplet_model(X3)\n",
        "\n",
        "concat_vector=concatenate([encoded1,encoded2,encoded3],axis=-1,name='concat')\n",
        "model=Model(inputs=[X1,X2,X3],outputs=concat_vector)\n",
        "model.compile(loss=triplet_loss,optimizer=Adam(0.00001))\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model (Model)                   (None, 256)          21137472    input_4[0][0]                    \n",
            "                                                                 input_5[0][0]                    \n",
            "                                                                 input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concat (Concatenate)            (None, 768)          0           model[1][0]                      \n",
            "                                                                 model[2][0]                      \n",
            "                                                                 model[3][0]                      \n",
            "==================================================================================================\n",
            "Total params: 21,137,472\n",
            "Trainable params: 21,137,472\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwVwSYlM6fl_",
        "colab_type": "text"
      },
      "source": [
        "### First time Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxIEPYaBCC5r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "379d7cd2-597f-4966-c597-c4ea68ab1ba9"
      },
      "source": [
        "triples,targets=GetTriples(3000,True)\n",
        "Anchor = triples[0]\n",
        "Positive = triples[1]\n",
        "Negative = triples[2]\n",
        "Y=targets\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "\n",
        "mc = ModelCheckpoint('/content/drive/My Drive/WildAI/csv/best_model.h5', monitor='val_loss', mode='min')\n",
        "\n",
        "model.fit([Anchor,Positive,Negative],y=targets, batch_size=50, epochs=120,verbose=2,validation_split=0.1,callbacks=[es,mc])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2700 samples, validate on 300 samples\n",
            "Epoch 1/120\n",
            "2700/2700 - 71s - loss: 0.8946 - val_loss: 0.6864\n",
            "Epoch 2/120\n",
            "2700/2700 - 65s - loss: 0.7154 - val_loss: 0.5719\n",
            "Epoch 3/120\n",
            "2700/2700 - 66s - loss: 0.5994 - val_loss: 0.5004\n",
            "Epoch 4/120\n",
            "2700/2700 - 65s - loss: 0.5166 - val_loss: 0.4739\n",
            "Epoch 5/120\n",
            "2700/2700 - 65s - loss: 0.4613 - val_loss: 0.4493\n",
            "Epoch 6/120\n",
            "2700/2700 - 65s - loss: 0.4153 - val_loss: 0.4213\n",
            "Epoch 7/120\n",
            "2700/2700 - 65s - loss: 0.3926 - val_loss: 0.3885\n",
            "Epoch 8/120\n",
            "2700/2700 - 65s - loss: 0.3734 - val_loss: 0.3813\n",
            "Epoch 9/120\n",
            "2700/2700 - 66s - loss: 0.3594 - val_loss: 0.3709\n",
            "Epoch 10/120\n",
            "2700/2700 - 65s - loss: 0.3382 - val_loss: 0.3440\n",
            "Epoch 11/120\n",
            "2700/2700 - 66s - loss: 0.3215 - val_loss: 0.3178\n",
            "Epoch 12/120\n",
            "2700/2700 - 65s - loss: 0.2961 - val_loss: 0.2851\n",
            "Epoch 13/120\n",
            "2700/2700 - 65s - loss: 0.2837 - val_loss: 0.2869\n",
            "Epoch 14/120\n",
            "2700/2700 - 65s - loss: 0.2564 - val_loss: 0.2481\n",
            "Epoch 15/120\n",
            "2700/2700 - 66s - loss: 0.2355 - val_loss: 0.2314\n",
            "Epoch 16/120\n",
            "2700/2700 - 65s - loss: 0.2175 - val_loss: 0.2287\n",
            "Epoch 17/120\n",
            "2700/2700 - 65s - loss: 0.2031 - val_loss: 0.2070\n",
            "Epoch 18/120\n",
            "2700/2700 - 65s - loss: 0.1846 - val_loss: 0.1923\n",
            "Epoch 19/120\n",
            "2700/2700 - 65s - loss: 0.1698 - val_loss: 0.1821\n",
            "Epoch 20/120\n",
            "2700/2700 - 65s - loss: 0.1520 - val_loss: 0.1682\n",
            "Epoch 21/120\n",
            "2700/2700 - 65s - loss: 0.1371 - val_loss: 0.1494\n",
            "Epoch 22/120\n",
            "2700/2700 - 65s - loss: 0.1257 - val_loss: 0.1325\n",
            "Epoch 23/120\n",
            "2700/2700 - 65s - loss: 0.1153 - val_loss: 0.1263\n",
            "Epoch 24/120\n",
            "2700/2700 - 65s - loss: 0.1045 - val_loss: 0.1149\n",
            "Epoch 25/120\n",
            "2700/2700 - 65s - loss: 0.0991 - val_loss: 0.1210\n",
            "Epoch 26/120\n",
            "2700/2700 - 66s - loss: 0.0967 - val_loss: 0.1080\n",
            "Epoch 27/120\n",
            "2700/2700 - 65s - loss: 0.0926 - val_loss: 0.0969\n",
            "Epoch 28/120\n",
            "2700/2700 - 66s - loss: 0.0812 - val_loss: 0.0957\n",
            "Epoch 29/120\n",
            "2700/2700 - 65s - loss: 0.0732 - val_loss: 0.0898\n",
            "Epoch 30/120\n",
            "2700/2700 - 65s - loss: 0.0686 - val_loss: 0.0827\n",
            "Epoch 31/120\n",
            "2700/2700 - 66s - loss: 0.0616 - val_loss: 0.0727\n",
            "Epoch 32/120\n",
            "2700/2700 - 65s - loss: 0.0567 - val_loss: 0.0694\n",
            "Epoch 33/120\n",
            "2700/2700 - 65s - loss: 0.0535 - val_loss: 0.0712\n",
            "Epoch 34/120\n",
            "2700/2700 - 65s - loss: 0.0471 - val_loss: 0.0605\n",
            "Epoch 35/120\n",
            "2700/2700 - 65s - loss: 0.0433 - val_loss: 0.0570\n",
            "Epoch 36/120\n",
            "2700/2700 - 65s - loss: 0.0391 - val_loss: 0.0514\n",
            "Epoch 37/120\n",
            "2700/2700 - 65s - loss: 0.0356 - val_loss: 0.0493\n",
            "Epoch 38/120\n",
            "2700/2700 - 65s - loss: 0.0328 - val_loss: 0.0455\n",
            "Epoch 39/120\n",
            "2700/2700 - 65s - loss: 0.0287 - val_loss: 0.0436\n",
            "Epoch 40/120\n",
            "2700/2700 - 65s - loss: 0.0277 - val_loss: 0.0425\n",
            "Epoch 41/120\n",
            "2700/2700 - 65s - loss: 0.0253 - val_loss: 0.0425\n",
            "Epoch 42/120\n",
            "2700/2700 - 65s - loss: 0.0232 - val_loss: 0.0375\n",
            "Epoch 43/120\n",
            "2700/2700 - 65s - loss: 0.0209 - val_loss: 0.0367\n",
            "Epoch 44/120\n",
            "2700/2700 - 65s - loss: 0.0208 - val_loss: 0.0343\n",
            "Epoch 45/120\n",
            "2700/2700 - 65s - loss: 0.0188 - val_loss: 0.0337\n",
            "Epoch 46/120\n",
            "2700/2700 - 65s - loss: 0.0179 - val_loss: 0.0312\n",
            "Epoch 47/120\n",
            "2700/2700 - 65s - loss: 0.0170 - val_loss: 0.0315\n",
            "Epoch 48/120\n",
            "2700/2700 - 65s - loss: 0.0159 - val_loss: 0.0301\n",
            "Epoch 49/120\n",
            "2700/2700 - 65s - loss: 0.0152 - val_loss: 0.0289\n",
            "Epoch 50/120\n",
            "2700/2700 - 65s - loss: 0.0147 - val_loss: 0.0274\n",
            "Epoch 51/120\n",
            "2700/2700 - 66s - loss: 0.0133 - val_loss: 0.0268\n",
            "Epoch 52/120\n",
            "2700/2700 - 65s - loss: 0.0121 - val_loss: 0.0230\n",
            "Epoch 53/120\n",
            "2700/2700 - 65s - loss: 0.0118 - val_loss: 0.0223\n",
            "Epoch 54/120\n",
            "2700/2700 - 65s - loss: 0.0105 - val_loss: 0.0215\n",
            "Epoch 55/120\n",
            "2700/2700 - 65s - loss: 0.0097 - val_loss: 0.0205\n",
            "Epoch 56/120\n",
            "2700/2700 - 66s - loss: 0.0097 - val_loss: 0.0210\n",
            "Epoch 57/120\n",
            "2700/2700 - 65s - loss: 0.0084 - val_loss: 0.0212\n",
            "Epoch 58/120\n",
            "2700/2700 - 65s - loss: 0.0077 - val_loss: 0.0203\n",
            "Epoch 59/120\n",
            "2700/2700 - 65s - loss: 0.0079 - val_loss: 0.0199\n",
            "Epoch 60/120\n",
            "2700/2700 - 65s - loss: 0.0079 - val_loss: 0.0200\n",
            "Epoch 61/120\n",
            "2700/2700 - 65s - loss: 0.0068 - val_loss: 0.0203\n",
            "Epoch 62/120\n",
            "2700/2700 - 66s - loss: 0.0069 - val_loss: 0.0203\n",
            "Epoch 63/120\n",
            "2700/2700 - 65s - loss: 0.0065 - val_loss: 0.0191\n",
            "Epoch 64/120\n",
            "2700/2700 - 65s - loss: 0.0057 - val_loss: 0.0180\n",
            "Epoch 65/120\n",
            "2700/2700 - 65s - loss: 0.0051 - val_loss: 0.0173\n",
            "Epoch 66/120\n",
            "2700/2700 - 65s - loss: 0.0053 - val_loss: 0.0187\n",
            "Epoch 67/120\n",
            "2700/2700 - 65s - loss: 0.0047 - val_loss: 0.0169\n",
            "Epoch 68/120\n",
            "2700/2700 - 65s - loss: 0.0050 - val_loss: 0.0189\n",
            "Epoch 69/120\n",
            "2700/2700 - 65s - loss: 0.0055 - val_loss: 0.0174\n",
            "Epoch 70/120\n",
            "2700/2700 - 65s - loss: 0.0050 - val_loss: 0.0151\n",
            "Epoch 71/120\n",
            "2700/2700 - 65s - loss: 0.0042 - val_loss: 0.0166\n",
            "Epoch 72/120\n",
            "2700/2700 - 66s - loss: 0.0045 - val_loss: 0.0171\n",
            "Epoch 73/120\n",
            "2700/2700 - 65s - loss: 0.0038 - val_loss: 0.0153\n",
            "Epoch 74/120\n",
            "2700/2700 - 65s - loss: 0.0035 - val_loss: 0.0158\n",
            "Epoch 75/120\n",
            "2700/2700 - 65s - loss: 0.0039 - val_loss: 0.0172\n",
            "Epoch 76/120\n",
            "2700/2700 - 65s - loss: 0.0035 - val_loss: 0.0154\n",
            "Epoch 77/120\n",
            "2700/2700 - 65s - loss: 0.0033 - val_loss: 0.0143\n",
            "Epoch 78/120\n",
            "2700/2700 - 66s - loss: 0.0040 - val_loss: 0.0148\n",
            "Epoch 79/120\n",
            "2700/2700 - 65s - loss: 0.0033 - val_loss: 0.0147\n",
            "Epoch 80/120\n",
            "2700/2700 - 65s - loss: 0.0034 - val_loss: 0.0142\n",
            "Epoch 81/120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP4_jnqBUriC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model.save_weights(\"ind-model.h5\")\n",
        "#trained_model=Model(inputs=X1,outputs=encoded1)\n",
        "#trained_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#trained_model.load_weights(\"ind-model.h5\")\n",
        "#trained_model.load_weights(\"/content/drive/My Drive/U C Berkeley - Darragh/csv/best_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RA5fgtqA7G_b",
        "colab_type": "text"
      },
      "source": [
        "### EValuate /Test trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND3Rd1vtbvY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load previously trained model\n",
        "trained_model=Model(inputs=X1,outputs=encoded1)\n",
        "trained_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#trained_model.load_weights(\"ind-model.h5\")\n",
        "trained_model.load_weights(\"/content/drive/My Drive/WildAI/csv/best_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-EY6WqtFvQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Test Results\n",
        "\n",
        "#trained_model.load_weights(\"best-model.h5\")\n",
        "knns=FitKNNs(Ind_DB,trained_model)\n",
        "\n",
        "\n",
        "X_Test_encoded=trained_model.predict(X_Test)\n",
        "num=len(X_Test_encoded)\n",
        "count=defaultdict(int)\n",
        "correct_count=defaultdict(int)\n",
        "correct=0\n",
        "for i in range(num):\n",
        "  #X_encoded=trained_mode.predict(X_Test[i])  \n",
        "  x=X_Test_encoded[i]\n",
        "  species=Species_Test[i]\n",
        "  count[species]+=1\n",
        "  true=Individuals_Test[i]\n",
        "  predicted=predict(knns[species],x.reshape(1,-1))\n",
        "  #predicted=predict(knns[species],pcas[species],x.reshape(1,-1))\n",
        "  if true==predicted[0]:\n",
        "    correct=correct+1\n",
        "    correct_count[species]+=1\n",
        "  else:\n",
        "    print(predicted[0],'  ----    ',true)\n",
        "Accuracy=correct/num\n",
        "print(\"Overall Accuracy = \",Accuracy)\n",
        "for species in count.keys():\n",
        "  print(\"Accuracy for \",species,\": \",correct_count[species]/count[species] )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoSlq598V7jt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ALternate prediction (WORK IN PROGRESS)\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "def norm_predict(x):\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sbZe3zUM7lm",
        "colab_type": "text"
      },
      "source": [
        "## Visualization of Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzY-gwBiM-QS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtfgxoU40ozV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y=le.transform(Species)\n",
        "X_encoded=trained_model.predict(X)\n",
        "le.classes_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wyiC30o6OL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1=pd.DataFrame(X_encoded)\n",
        "df1['y']=Y\n",
        "df1['Names']=Individuals \n",
        "df_ATiger=df1[df1.y==0]\n",
        "\n",
        "df_BTiger=df1[df1.y==1]\n",
        "\n",
        "df_BRhino=df1[df1.y==2]\n",
        "\n",
        "df_Cheetah=df1[df1.y==3]\n",
        "\n",
        "df_Leopard=df1[df1.y==4]\n",
        "\n",
        "df_LTapir=df1[df1.y==5]\n",
        "\n",
        "df_Puma=df1[df1.y==6]\n",
        "\n",
        "df_WRhino=df1[df1.y==7]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9j290kM6duU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotprints(df):\n",
        "  dfx=df.drop(['y','Names'],axis=1)\n",
        "  tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
        "  tsne_results = tsne.fit_transform(dfx)\n",
        "  df['tsne-2d-one'] = tsne_results[:,0]\n",
        "  df['tsne-2d-two'] = tsne_results[:,1]\n",
        "  plt.figure(figsize=(16,10))\n",
        "  num=df['Names'].nunique()\n",
        "\n",
        "  sns.scatterplot(x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
        "                  hue=\"Names\",\n",
        "                  palette=sns.color_palette(\"hls\", num),\n",
        "                  data=df,\n",
        "                  legend=\"full\",\n",
        "                  alpha=0.6)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDd0RrSeIHkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot projected 2D clusters for each specis\n",
        "plotprints(df_WRhino)\n",
        "plotprints(df_BRhino)\n",
        "plotprints(df_ATiger)\n",
        "plotprints(df_BTiger)\n",
        "plotprints(df_Puma)\n",
        "plotprints(df_Cheetah)\n",
        "plotprints(df_Leopard)\n",
        "plotprints(df_LTapir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PM6fb0vDbhAa",
        "colab_type": "text"
      },
      "source": [
        "# MobileNetV2 - UNDER CONSTRUCTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KH_RONF7hgM",
        "colab_type": "text"
      },
      "source": [
        "Placeholder Section to reproduce work done above (with VGG16) using MobileNet V2 . \n",
        "Note: INCOMPLETE: Needs to be completed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfYuX5Cncmm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape=(224,224,3)\n",
        "mnet=MobileNetV2(weights='imagenet',include_top=False,input_shape=input_shape)\n",
        "mnet.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScDUSDYnKDxn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Pre-Processed Images\n",
        "  csvpath='/content/drive/My Drive/U C Berkeley - Darragh/csv'\n",
        "  X,Species,Individuals, Ind_DB,X_Test,Species_Test,Individuals_Test=LoadData(\"Train-Images-Mobile-224.csv\",\"Train-Labels-Mobile-224.txt\",\"Test-Images-Mobile-224.csv\",\"Test-Labels-Mobile-224.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvdbsEjQfru1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "le = LabelEncoder()\n",
        "le.fit(Species)\n",
        "Y=le.transform(Species)\n",
        "Y_Test=le.transform(Species_Test)\n",
        "Y1=to_categorical(np.array(Y))\n",
        "Y_Test1=to_categorical(np.array(Y_Test))\n",
        "print(Y1.shape)\n",
        "print(le.classes_)\n",
        "#For Species Classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_Train, X_Val, Y_Train, Y_Val = train_test_split(X, Y1, test_size=0.10, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ej2rXtYhDbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "mnet_model=Sequential()\n",
        "mnet_model.add(mnet)\n",
        "mnet_model.add(Flatten())\n",
        "mnet_model.add(Dense(128, activation='relu',name=\"Dense1\"))\n",
        "mnet_model.add(Dense(64, activation='relu',name=\"Dense2\"))\n",
        "mnet_model.add(Dropout(0.8))\n",
        "mnet_model.add(Dense(8))\n",
        "\n",
        "mnet_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G22beqV1gef2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "mnet_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.00001),\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])\n",
        "mnet_model.fit(X_Train,Y_Train,validation_data=(X_Val,Y_Val),epochs=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVbHX4EOiCIT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnet_model.evaluate(X_Test,  Y_Test1, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMGEpl9ZAstg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QtyjVIhltb0",
        "colab_type": "text"
      },
      "source": [
        "### Identification Task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2Ma_mKBmMfb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnet_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kwcbF09mKYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "triplet_model=Model(inputs=mnet_model.input,outputs=mnet_model.get_layer('Dense1').output)\n",
        "triplet_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x90nuj1mfzT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape=[224,224,3]\n",
        "X1=Input(input_shape)\n",
        "X2=Input(input_shape)\n",
        "X3=Input(input_shape)\n",
        "encoded1 = triplet_model(X1)\n",
        "encoded2 = triplet_model(X2)\n",
        "encoded3 = triplet_model(X3)\n",
        "\n",
        "concat_vector=concatenate([encoded1,encoded2,encoded3],axis=-1,name='concat')\n",
        "model=Model(inputs=[X1,X2,X3],outputs=concat_vector)\n",
        "model.compile(loss=triplet_loss,optimizer=Adam(0.00001))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCGE5istmwka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "triples,targets=GetTriples(1500,True)\n",
        "Anchor = triples[0]\n",
        "Positive = triples[1]\n",
        "Negative = triples[2]\n",
        "Y=targets\n",
        "\n",
        "model.fit([Anchor,Positive,Negative],y=targets, batch_size=40, epochs=60,verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ00kHl8sTe2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(\"ind-model-mnet.h5\")\n",
        "trained_model=Model(inputs=X1,outputs=encoded1)\n",
        "trained_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "trained_model.load_weights(\"ind-model-mnet.h5\")\n",
        "\n",
        "num=len(X_Test)\n",
        "correct=0\n",
        "X_encoded=trained_model.predict(X_Test)\n",
        "\n",
        "for i in range(num):\n",
        "  #img=x = np.expand_dims(X_Test[i], axis=0)\n",
        "  #X_encoded=trained_model.predict(X_Test[i])  \n",
        "  test_data=[X_encoded[i],Species_Test[i]]\n",
        "  true=Individuals_Test[i]\n",
        "  predicted,silver,bronze=Validate(test_data,Ind_DB,trained_model)\n",
        "  print(true,predicted,silver,bronze)\n",
        "  if true==predicted:\n",
        "    correct=correct+1\n",
        "Accuracy=correct/num\n",
        "print(\"Accuracy = \",Accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}