{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WildAI-Individual_ID_Training.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "MQkh5YUBHmA3",
        "2Z60Ev8dID4V",
        "oUpXvJ0rJr3h"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA2Q3Tn6YPbN",
        "colab_type": "text"
      },
      "source": [
        "# Wildtrack AI - Individual Identification Model Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_4ipmAXGblm",
        "colab_type": "text"
      },
      "source": [
        "# 1. Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVEyGQQmufJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Set up Tensor flow 2.0\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u-mWgHlgum4P",
        "outputId": "2f85ceae-7063-49ad-f5bc-875c53abfead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "#General\n",
        "import cv2\n",
        "import csv\n",
        "import os\n",
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "import pandas as pd\n",
        "from google.colab.patches import cv2_imshow\n",
        "from collections import defaultdict\n",
        "import random\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "import pickle\n",
        "\n",
        "# TF2.0/ Keras Libraries\n",
        "\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Keras Imagenet pre=-trained models and pre-processors\n",
        "from keras.preprocessing import image as KImage\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input as VGG16Pre\n",
        "\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.applications.xception import preprocess_input as XceptionPre\n",
        "\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as MNPre\n",
        "\n",
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
        "\n",
        "\n",
        "# TF2/ Keras Modeling utilities\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D, BatchNormalization, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.layers import Lambda, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import he_normal\n",
        "from tensorflow.keras.initializers import lecun_normal\n",
        "from tensorflow.keras.initializers import he_uniform\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.initializers import glorot_normal\n",
        "\n",
        "\n",
        "\n",
        "# Plotting/ Visualization\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOq_0bZOKqT8",
        "colab_type": "code",
        "outputId": "a0cd6386-5b46-4f6b-896b-2b9893aabf42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#Mount Google Drive - Note this mounts your personal GDrive to the directory stated\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnMiJs14liW7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Set up various paths\n",
        "#Set up path for csv files containing preprocessed images. CHange subfolder names to match your setup in google drive\n",
        "csvpath='/content/drive/My Drive/U C Berkeley - Darragh/csv'\n",
        "path=\"/content/drive/My Drive/U C Berkeley - Darragh/Training Data\"\n",
        "test_path=\"/content/drive/My Drive/U C Berkeley - Darragh/Test Data\"\n",
        "modelpath='/content/drive/My Drive/WildAI/csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJpw6HR34887",
        "colab_type": "text"
      },
      "source": [
        "## 2. Load Images and setup Data Structures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQkh5YUBHmA3",
        "colab_type": "text"
      },
      "source": [
        "### 2-1. Load Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH7OT1efHqFG",
        "colab_type": "text"
      },
      "source": [
        "Previously pre-processed images are loaded from csv files. The pre-processing is done per the input requirements for the model being used.  Pre-processing implementation can be found here: https://colab.research.google.com/drive/1tVg9y71wbf_-bpgOue4LAFbCSXuu2SCD?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdcruOUPwdGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BASE_MODEL=\"vgg16\"  #CHoices are: vgg16, mobilenetv2, Xception\n",
        "\n",
        "if BASE_MODEL=='vgg16':\n",
        "  train_imagefile=\"Training-Images-224.csv\"\n",
        "  train_labelfile=\"Training-Labels-224.txt\"\n",
        "  test_imagefile=\"Test-Images-224.csv\"\n",
        "  test_labelfile=\"Test-Labels-224.txt\"\n",
        "  input_shape=(224,224,3)\n",
        "  pretrained_model='species_classification_vgg16_model.h5'\n",
        "  preprocessor=VGG16Pre\n",
        "  savefile='vgg16_best_model'\n",
        "  savemodel='vgg16_best_model.h5'\n",
        "elif BASE_MODEL==\"mobilenetv2\":\n",
        "  train_imagefile=\"Train-Images-Mobile-224.csv\"\n",
        "  train_labelfile=\"Train-Labels-Mobile-224.txt\"\n",
        "  test_imagefile=\"Test-Images-Mobile-224.csv\"\n",
        "  test_labelfile=\"Test-Labels-Mobile-224.txt\"\n",
        "  input_shape=(224,224,3)\n",
        "  pretrained_model='species_classification_mobilenetv2_model.h5'\n",
        "  preprocessor=MNPre\n",
        "  savefile='mobilenetv2_best_model'\n",
        "elif BASE_MODEL==\"xception\":\n",
        "  train_imagefile=\"Training-Images-Xception-224.csv\"\n",
        "  train_labelfile=\"Training-Labels-Xception-224.txt\"\n",
        "  test_imagefile=\"Test-Images-Xception-224.csv\"\n",
        "  test_labelfile=\"Test-Labels-Xception-224.txt\"\n",
        "  input_shape=(224,224,3)\n",
        "  pretrained_model='species_classification_xception_model.h5'\n",
        "  preprocessor=XceptionPre\n",
        "  savefile='xception_best_model'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39LcbZgrd4Pn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to load processed image data in csv files (both training and test, input data labels)\n",
        "def LoadData(train_imagefile=train_imagefile,train_labelfile=train_labelfile,\n",
        "             test_imagefile=test_imagefile,test_labelfile=test_labelfile):\n",
        "  #Training Data Set\n",
        "  Ind_DB=defaultdict(defaultdict)\n",
        "  Individuals=[]\n",
        "  Species=[]\n",
        "  X=[]\n",
        "  dataset=np.loadtxt(os.path.join(csvpath,train_imagefile),delimiter=\",\")\n",
        "  f=open(os.path.join(csvpath,train_labelfile),'r')\n",
        "  lines=f.readlines()\n",
        "  for line in lines:\n",
        "    vals=line.rstrip()\n",
        "    Species.append(vals.split(\"-\")[0])\n",
        "    Individuals.append(vals)\n",
        "  f.close()\n",
        "    \n",
        "  i=0\n",
        "  for x in dataset:\n",
        "    image=x.reshape(224,224,3)\n",
        "    X.append(image)\n",
        "    species=Species[i]\n",
        "    key=Individuals[i]\n",
        "    spec_DB=Ind_DB[species]\n",
        "    if key not in spec_DB.keys():\n",
        "      spec_DB[key]=[image]\n",
        "    else:\n",
        "      spec_DB[key].append(image)\n",
        "    i=i+1\n",
        "\n",
        "\n",
        "  #Test Data Set\n",
        "  X_Test=[]\n",
        "  Individuals_Test=[]\n",
        "  Species_Test=[]\n",
        "  dataset=np.loadtxt(os.path.join(csvpath,test_imagefile),delimiter=\",\")\n",
        "\n",
        "  for x in dataset:\n",
        "    image=x.reshape(224,224,3)\n",
        "    X_Test.append(image)\n",
        "\n",
        "  f=open(os.path.join(csvpath,test_labelfile),'r')\n",
        "  lines=f.readlines()\n",
        "  for line in lines:\n",
        "    vals=line.rstrip()\n",
        "    Species_Test.append(vals.split(\"-\")[0])\n",
        "    Individuals_Test.append(vals)\n",
        "  f.close()\n",
        "\n",
        "  X_Test=np.asarray(X_Test)\n",
        "    \n",
        "  return (Ind_DB,X_Test,Species_Test,Individuals_Test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSfK_bzXNAjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Pre-Processed Images\n",
        "Ind_DB,X_Test,Species_Test,Individuals_Test=LoadData(train_imagefile=train_imagefile, train_labelfile=train_labelfile,\n",
        "                                                     test_imagefile=test_imagefile, test_labelfile=test_labelfile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z60Ev8dID4V",
        "colab_type": "text"
      },
      "source": [
        "### 2-2. Generate Triples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8kifSoLINfn",
        "colab_type": "text"
      },
      "source": [
        "A \"triple\" is defined as 2 footprints for the same individual, one for a different individual - all withing the same species. This section generates all possible triples from the data we have and writes them back out to a file, splitting out a subsection for validation/ dev. \n",
        "During Model training/evaluation, triples definitions are read back out from this file to generate training/ validation data.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pwl5J8PClXSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function create triples (A1,A2,B) for individuals within a species. All possible combinations are enumerated and written back to file\n",
        "\n",
        "Species=[]\n",
        "\n",
        "# Given a pair, add distinct footprint to create triples\n",
        "def UpdateTriples(doubles,footprint):\n",
        "  new_triples=[]\n",
        "  for double in doubles:\n",
        "    if double[0]==footprint or double[1]==footprint:\n",
        "      print(\"Error in Update: \",double,footprint)\n",
        "    new_triples.append((double[0],double[1],footprint))\n",
        "  return new_triples\n",
        "\n",
        "def AddTriples(singles,previous,footprint):\n",
        "  new_triples=[]\n",
        "  new_doubles=[]\n",
        "\n",
        "  for base in previous:\n",
        "    new_doubles.append((base,footprint))\n",
        "    for single in singles:\n",
        "      if base==single or footprint==single:\n",
        "        print(\"Error in add: \",base,footprint,single)\n",
        "      new_triples.append((base,footprint,single))\n",
        "  return new_doubles,new_triples\n",
        "\n",
        "\n",
        "# Function to go through each species and generate triples \n",
        "# that are then written back out to file. \n",
        "\n",
        "def LoadDataSet(DB,output_folder,outfile):\n",
        "  for species in DB.keys():\n",
        "\n",
        "    Species.append(species)\n",
        "    filename=outfile+\"_\"+species+\".csv\"\n",
        "    f = open(os.path.join(output_folder,filename),\"w\")\n",
        "    writer = csv.writer(f)\n",
        "\n",
        "    print(\"\\n\\n*** SPECIES:  \",species)\n",
        "\n",
        "    triples=[]\n",
        "    doubles=[]\n",
        "    singles=[]\n",
        "    individuals=DB[species]\n",
        "\n",
        "    for individual,printlist in individuals.items():\n",
        "      print(\"\\n* INDIVIDUAL: \",individual)\n",
        "      previous=[]\n",
        "      prev_doubles=[]\n",
        "      num_prints=len(printlist)\n",
        "\n",
        "      for i in range(num_prints):\n",
        "        uniq_print=individual+'|'+str(i)\n",
        "        new_triples1=UpdateTriples(doubles,uniq_print)\n",
        "        new_doubles,new_triples2=AddTriples(singles,previous,uniq_print)\n",
        "        prev_doubles.extend(new_doubles)\n",
        "        for triple in new_triples1:\n",
        "          writer.writerow(triple)\n",
        "        for triple in new_triples2:\n",
        "          writer.writerow(triple)\n",
        "        previous.append(uniq_print)\n",
        "      doubles.extend(prev_doubles)\n",
        "      singles.extend(previous)\n",
        "    f.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ8LDjblwvaF",
        "colab_type": "code",
        "outputId": "3ae35b90-7c66-4c7e-b91d-c92c38744c31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Create Triples\n",
        "LoadDataSet(Ind_DB,csvpath,\"triples\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "*** SPECIES:   Amur Tiger\n",
            "\n",
            "* INDIVIDUAL:  Amur Tiger-261\n",
            "\n",
            "* INDIVIDUAL:  Amur Tiger-237\n",
            "\n",
            "* INDIVIDUAL:  Amur Tiger-279\n",
            "\n",
            "* INDIVIDUAL:  Amur Tiger-440\n",
            "\n",
            "* INDIVIDUAL:  Amur Tiger-565\n",
            "\n",
            "* INDIVIDUAL:  Amur Tiger-682\n",
            "\n",
            "* INDIVIDUAL:  Amur Tiger-1020\n",
            "\n",
            "\n",
            "*** SPECIES:   Bengal Tiger\n",
            "\n",
            "* INDIVIDUAL:  Bengal Tiger-Aria\n",
            "\n",
            "* INDIVIDUAL:  Bengal Tiger-Fenimore\n",
            "\n",
            "* INDIVIDUAL:  Bengal Tiger-India\n",
            "\n",
            "* INDIVIDUAL:  Bengal Tiger-Lucky\n",
            "\n",
            "* INDIVIDUAL:  Bengal Tiger-Moki\n",
            "\n",
            "* INDIVIDUAL:  Bengal Tiger-Mona\n",
            "\n",
            "* INDIVIDUAL:  Bengal Tiger-Rajah\n",
            "\n",
            "* INDIVIDUAL:  Bengal Tiger-Rajaji\n",
            "\n",
            "\n",
            "*** SPECIES:   Cheetah\n",
            "\n",
            "* INDIVIDUAL:  Cheetah-Aiko\n",
            "\n",
            "* INDIVIDUAL:  Cheetah-Alvin\n",
            "\n",
            "* INDIVIDUAL:  Cheetah-Chiquita\n",
            "\n",
            "* INDIVIDUAL:  Cheetah-Jamu\n",
            "\n",
            "* INDIVIDUAL:  Cheetah-Kiki\n",
            "\n",
            "* INDIVIDUAL:  Cheetah-Pano\n",
            "\n",
            "* INDIVIDUAL:  Cheetah-Rusty\n",
            "\n",
            "* INDIVIDUAL:  Cheetah-Sandy\n",
            "\n",
            "* INDIVIDUAL:  Cheetah-Tearmark\n",
            "\n",
            "\n",
            "*** SPECIES:   Leopard\n",
            "\n",
            "* INDIVIDUAL:  Leopard-Keanu\n",
            "\n",
            "* INDIVIDUAL:  Leopard-Lewa\n",
            "\n",
            "* INDIVIDUAL:  Leopard-Mick\n",
            "\n",
            "* INDIVIDUAL:  Leopard-Ombeli\n",
            "\n",
            "* INDIVIDUAL:  Leopard-Timbila\n",
            "\n",
            "* INDIVIDUAL:  Leopard-Tony\n",
            "\n",
            "* INDIVIDUAL:  Leopard-Wahoo\n",
            "\n",
            "* INDIVIDUAL:  Leopard-Shakira\n",
            "\n",
            "\n",
            "*** SPECIES:   Lowland Tapir\n",
            "\n",
            "* INDIVIDUAL:  Lowland Tapir-Sorocaba 2\n",
            "\n",
            "* INDIVIDUAL:  Lowland Tapir-Chuva F\n",
            "\n",
            "* INDIVIDUAL:  Lowland Tapir-Sorocaba 5\n",
            "\n",
            "* INDIVIDUAL:  Lowland Tapir-Edinha F\n",
            "\n",
            "* INDIVIDUAL:  Lowland Tapir-Feminha F\n",
            "\n",
            "* INDIVIDUAL:  Lowland Tapir-Pistolinha M\n",
            "\n",
            "* INDIVIDUAL:  Lowland Tapir-Sorocaba\n",
            "\n",
            "* INDIVIDUAL:  Lowland Tapir-Chuvisco M\n",
            "\n",
            "* INDIVIDUAL:  Lowland Tapir-Riscado M\n",
            "\n",
            "\n",
            "*** SPECIES:   Puma\n",
            "\n",
            "* INDIVIDUAL:  Puma-M-Taz\n",
            "\n",
            "* INDIVIDUAL:  Puma-M-Skit\n",
            "\n",
            "* INDIVIDUAL:  Puma-M-Pops\n",
            "\n",
            "* INDIVIDUAL:  Puma-M-Phoenix\n",
            "\n",
            "* INDIVIDUAL:  Puma-M-Oldex\n",
            "\n",
            "* INDIVIDUAL:  Puma-M-Juvboy\n",
            "\n",
            "* INDIVIDUAL:  Puma-M-Darby\n",
            "\n",
            "* INDIVIDUAL:  Puma-F-Tawny\n",
            "\n",
            "* INDIVIDUAL:  Puma-F-Spots\n",
            "\n",
            "* INDIVIDUAL:  Puma-F-Majanna\n",
            "\n",
            "* INDIVIDUAL:  Puma-F-Lip\n",
            "\n",
            "* INDIVIDUAL:  Puma-F-Cassie\n",
            "\n",
            "* INDIVIDUAL:  Puma-F-Archback\n",
            "\n",
            "\n",
            "*** SPECIES:   White Rhino\n",
            "\n",
            "* INDIVIDUAL:  White Rhino-Kalakwa Cs10\n",
            "\n",
            "* INDIVIDUAL:  White Rhino-Kalakwa Cs5\n",
            "\n",
            "* INDIVIDUAL:  White Rhino-Kalakwa Cs15\n",
            "\n",
            "* INDIVIDUAL:  White Rhino-Kalakwa Cs6\n",
            "\n",
            "* INDIVIDUAL:  White Rhino-Kal Cs 9JunKML3\n",
            "\n",
            "* INDIVIDUAL:  White Rhino-Kal Cs 6JunKML2\n",
            "\n",
            "* INDIVIDUAL:  White Rhino-Kalakwa Cs7\n",
            "\n",
            "* INDIVIDUAL:  White Rhino-Kalakwa Cs17\n",
            "\n",
            "\n",
            "*** SPECIES:   Black Rhino\n",
            "\n",
            "* INDIVIDUAL:  Black Rhino-Kal Db Himb\n",
            "\n",
            "* INDIVIDUAL:  Black Rhino-Kal Db Jav\n",
            "\n",
            "* INDIVIDUAL:  Black Rhino-Kal Db Kuz\n",
            "\n",
            "* INDIVIDUAL:  Black Rhino-Kal Db M1\n",
            "\n",
            "* INDIVIDUAL:  Black Rhino-Kal Db M2\n",
            "\n",
            "* INDIVIDUAL:  Black Rhino-Kuz Db Col\n",
            "\n",
            "* INDIVIDUAL:  Black Rhino-Kuz Db Hec\n",
            "\n",
            "* INDIVIDUAL:  Black Rhino-Kuz Db Hel\n",
            "\n",
            "* INDIVIDUAL:  Black Rhino-Kuz Db Ken\n",
            "\n",
            "\n",
            "*** SPECIES:   African lion\n",
            "\n",
            "* INDIVIDUAL:  African lion-Jamu\n",
            "\n",
            "* INDIVIDUAL:  African lion-Mogli\n",
            "\n",
            "* INDIVIDUAL:  African lion-Ceasar\n",
            "\n",
            "* INDIVIDUAL:  African lion-Maro\n",
            "\n",
            "* INDIVIDUAL:  African lion-Jan\n",
            "\n",
            "* INDIVIDUAL:  African lion-Elsa\n",
            "\n",
            "* INDIVIDUAL:  African lion-Inca\n",
            "\n",
            "* INDIVIDUAL:  African lion-Elangeny\n",
            "\n",
            "* INDIVIDUAL:  African lion-Mapivu\n",
            "\n",
            "* INDIVIDUAL:  African lion-Bijan\n",
            "\n",
            "\n",
            "*** SPECIES:   African elephant\n",
            "\n",
            "* INDIVIDUAL:  African elephant-Mashudu\n",
            "\n",
            "* INDIVIDUAL:  African elephant-Abu\n",
            "\n",
            "* INDIVIDUAL:  African elephant-Thandi\n",
            "\n",
            "* INDIVIDUAL:  African elephant-Chikenya\n",
            "\n",
            "* INDIVIDUAL:  African elephant-Lorato\n",
            "\n",
            "* INDIVIDUAL:  African elephant-Sukeri\n",
            "\n",
            "* INDIVIDUAL:  African elephant-Sene\n",
            "\n",
            "* INDIVIDUAL:  African elephant-Thato\n",
            "\n",
            "* INDIVIDUAL:  African elephant-Paseka\n",
            "\n",
            "\n",
            "*** SPECIES:   Bongo\n",
            "\n",
            "* INDIVIDUAL:  Bongo-Rehema\n",
            "\n",
            "* INDIVIDUAL:  Bongo-Lucy\n",
            "\n",
            "* INDIVIDUAL:  Bongo-Kalama\n",
            "\n",
            "* INDIVIDUAL:  Bongo-Nolano\n",
            "\n",
            "* INDIVIDUAL:  Bongo-Bambi\n",
            "\n",
            "* INDIVIDUAL:  Bongo-Malaika\n",
            "\n",
            "* INDIVIDUAL:  Bongo-Nengese\n",
            "\n",
            "* INDIVIDUAL:  Bongo-Amani\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2fIEq9xCSvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SPlit out Test vs Validation Data for triples\n",
        "from sklearn.model_selection import train_test_split\n",
        "for species in Species:\n",
        "  fname='triples_'+species+'.csv'\n",
        "  dataset=pd.read_csv(os.path.join(csvpath,fname),header=None)\n",
        "  trainset,devset = train_test_split(dataset, test_size=0.25, random_state=42)\n",
        "  fname='triples_'+species+'_train.csv'\n",
        "  trainset.to_csv(os.path.join(csvpath,fname))\n",
        "  fname='triples_'+species+'_dev.csv'\n",
        "  devset.to_csv(os.path.join(csvpath,fname))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUpXvJ0rJr3h",
        "colab_type": "text"
      },
      "source": [
        "### 2-3. Label Encoding for Species"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aan_gNm77C3w",
        "colab_type": "code",
        "outputId": "5f4eeecf-99a8-49a1-daea-b73d0dd45da8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Create Label Encoding for Species\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "le = LabelEncoder()\n",
        "le.fit(Species)\n",
        "Y=le.transform(Species)\n",
        "print(le.classes_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['African elephant' 'African lion' 'Amur Tiger' 'Bengal Tiger'\n",
            " 'Black Rhino' 'Bongo' 'Cheetah' 'Leopard' 'Lowland Tapir' 'Puma'\n",
            " 'White Rhino']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-vnCtF1YyBQ",
        "colab_type": "text"
      },
      "source": [
        "## 3. Model Set up "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffwUK27S-T7p",
        "colab_type": "text"
      },
      "source": [
        "Reference implementation for Individual Identification done with VGG16 pretrained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPPotfxT4UKa",
        "colab_type": "text"
      },
      "source": [
        "### 3-1. Common Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "No7wdcruFRwb",
        "colab": {}
      },
      "source": [
        "# Function returns image array given species and key\n",
        "\n",
        "def get_img(DB,species,key):\n",
        "  #print(key)\n",
        "  pipe='|'\n",
        "  values=key.split(pipe)\n",
        "  individual=values[0]\n",
        "  indx=int(values[1])\n",
        "  try:\n",
        "    spec_DB=DB[species]\n",
        "    imglist=spec_DB[individual]\n",
        "    x=imglist[indx]\n",
        "  except:\n",
        "    print(\"Error with loading \",key)  \n",
        "    x=np.zeros((224,224,3))\n",
        "\n",
        "  return x\n",
        "\n",
        "\n",
        "# Model Generator class to generate triple sets of images for a given species, \n",
        "# given batch size adn number of steps.\n",
        "\n",
        "def triples_generator(folder,DB,species,dataset=\"train\",batch_size=32,num_steps=100):\n",
        "  fname='triples_'+str(species)+'_'+dataset+'.csv'\n",
        "  df=pd.read_csv(os.path.join(folder,fname))\n",
        "  target=np.zeros((batch_size,768))\n",
        "  total=df.shape[0]\n",
        "  sample_size=int(num_steps*batch_size)\n",
        "\n",
        "  while 1:\n",
        "    indices=np.random.randint(0,total,size=sample_size)\n",
        "\n",
        "    for i in range(num_steps):\n",
        "      triples=[np.zeros((batch_size,224,224,3))for i in range(3)]\n",
        "      cnt=0\n",
        "\n",
        "      for j in range((i*batch_size),((i+1)*batch_size)):\n",
        "        k=indices[j]\n",
        "        triples[0][cnt,:,:,:]=get_img(DB,species,df.iloc[k,1])\n",
        "        triples[1][cnt,:,:,:]=get_img(DB,species,df.iloc[k,2])\n",
        "        triples[2][cnt,:,:,:]=get_img(DB,species,df.iloc[k,3])\n",
        "        cnt=cnt+1\n",
        "\n",
        "      yield (triples, target)\n",
        "\n",
        "\n",
        "#CUstom loss function for Triplets Network\n",
        "def triplet_loss(y_true,y_pred,alpha=1.2):\n",
        "  ln=y_pred.shape.as_list()[-1]\n",
        "  anchor=y_pred[:,0:int(ln/3)]\n",
        "  positive=y_pred[:,int(ln/3):int(2*ln/3)]\n",
        "  negative=y_pred[:,int(2*ln/3):ln]\n",
        "\n",
        "  p_dist=K.sqrt(K.sum(K.square(anchor-positive),axis=1))\n",
        "  n_dist=K.sqrt(K.sum(K.square(anchor-negative),axis=1))\n",
        "  loss=K.maximum(p_dist-n_dist+alpha,0.0)\n",
        "  return K.mean(loss)  \n",
        "\n",
        "#Return L2 Norm\n",
        "def calcl2(X,prints):\n",
        "  l2norm=[]\n",
        "  for i in range(len(prints)):\n",
        "    l2norm.append(np.linalg.norm(X - prints[i]))\n",
        "  return l2norm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiR7grte6YRh",
        "colab_type": "text"
      },
      "source": [
        "### 3-2. Set up Triplets Model functions for Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQWKFUUemKxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to create triplets model starting with a base model pre-trained as a species classifier\n",
        "\n",
        "def Create_TripletTrainer(csvpath,pretrained_model=pretrained_model,input_shape=(224,224,3)):\n",
        "  zero_model = load_model(os.path.join(csvpath,pretrained_model))\n",
        "  x=zero_model.get_layer('Embedding').output\n",
        "  x = Lambda(lambda  x: K.l2_normalize(x,axis=1))(x)\n",
        "  triplet_model=Model(inputs=zero_model.input,outputs=x)\n",
        "  input_shape=[224,224,3]\n",
        "  X1=Input(input_shape)\n",
        "  X2=Input(input_shape)\n",
        "  X3=Input(input_shape)\n",
        "  encoded1 = triplet_model(X1)\n",
        "  encoded2 = triplet_model(X2)\n",
        "  encoded3 = triplet_model(X3)\n",
        "\n",
        "  concat_vector=concatenate([encoded1,encoded2,encoded3],axis=-1,name='concat')\n",
        "  model=Model(inputs=[X1,X2,X3],outputs=concat_vector)\n",
        "  model.compile(loss=triplet_loss,optimizer=Adam(0.000005))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETTYJVN8Cbft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to Train a model for a given species using a pre-trained model as a base. \n",
        "# Trained model weights are saved to file passed into the savefile parameter. \n",
        "\n",
        "def TrainModel(DB,species=\"Leopard\",pretrained_model=pretrained_model,input_shape=(224,224,3),savefile=savefile):\n",
        "  tf.keras.backend.clear_session()\n",
        "\n",
        "  model=Create_TripletTrainer(modelpath,pretrained_model,input_shape=(224,224,3))\n",
        "\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "  chkpoint=savefile+'_'+str(species)+'.h5'\n",
        "  mc = ModelCheckpoint(os.path.join(modelpath,'testing',chkpoint), save_weights_only=True,monitor='val_loss', mode='min')\n",
        "  train_gen=triples_generator(csvpath,DB,species,dataset=\"train\",batch_size=50,num_steps=200)\n",
        "  val_gen=triples_generator(csvpath,DB,species,dataset=\"dev\",batch_size=50,num_steps=40)\n",
        "\n",
        "  print(\"Training for Species: \",species)\n",
        "  \n",
        "  model.fit(train_gen,steps_per_epoch=200, epochs=30,verbose=1,validation_data=val_gen,validation_steps=40,callbacks=[es,mc])\n",
        "  \n",
        "  return True\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUiR_yS0LdWX",
        "colab_type": "text"
      },
      "source": [
        "## 4. Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqeEue3xLgMu",
        "colab_type": "text"
      },
      "source": [
        "Train Model for each species and save weights to file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACBHYZrpU1-I",
        "colab_type": "code",
        "outputId": "ce998b3a-9520-4580-f185-5d20c4b160f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "TrainModel(Ind_DB,\"Amur Tiger\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "Training for Species:  Amur Tiger\n",
            "Epoch 1/30\n",
            "200/200 [==============================] - 236s 1s/step - loss: 0.8786 - val_loss: 0.3567\n",
            "Epoch 2/30\n",
            "200/200 [==============================] - 236s 1s/step - loss: 0.3062 - val_loss: 0.1396\n",
            "Epoch 3/30\n",
            "200/200 [==============================] - 235s 1s/step - loss: 0.1487 - val_loss: 0.1463\n",
            "Epoch 4/30\n",
            "200/200 [==============================] - 235s 1s/step - loss: 0.1334 - val_loss: 0.1096\n",
            "Epoch 5/30\n",
            "200/200 [==============================] - 236s 1s/step - loss: 0.0992 - val_loss: 0.0654\n",
            "Epoch 6/30\n",
            "200/200 [==============================] - 236s 1s/step - loss: 0.0795 - val_loss: 0.0711\n",
            "Epoch 7/30\n",
            "200/200 [==============================] - 236s 1s/step - loss: 0.0603 - val_loss: 0.0310\n",
            "Epoch 8/30\n",
            "200/200 [==============================] - 235s 1s/step - loss: 0.0213 - val_loss: 0.0051\n",
            "Epoch 9/30\n",
            "200/200 [==============================] - 235s 1s/step - loss: 0.0047 - val_loss: 0.0000e+00\n",
            "Epoch 10/30\n",
            "200/200 [==============================] - 235s 1s/step - loss: 6.4342e-04 - val_loss: 0.0000e+00\n",
            "Epoch 11/30\n",
            "200/200 [==============================] - 235s 1s/step - loss: 2.9557e-04 - val_loss: 0.0000e+00\n",
            "Epoch 12/30\n",
            "200/200 [==============================] - 235s 1s/step - loss: 2.5687e-04 - val_loss: 0.0000e+00\n",
            "Epoch 13/30\n",
            "200/200 [==============================] - 235s 1s/step - loss: 1.2340e-04 - val_loss: 0.0000e+00\n",
            "Epoch 14/30\n",
            "200/200 [==============================] - 235s 1s/step - loss: 1.0971e-04 - val_loss: 0.0000e+00\n",
            "Epoch 00014: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqmtr53XXB3S",
        "colab_type": "code",
        "outputId": "f00f4a41-ac47-43c1-e3ca-a01d4fa8a788",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "TrainModel(Ind_DB,\"Bengal Tiger\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "Training for Species:  Bengal Tiger\n",
            "Epoch 1/30\n",
            "200/200 [==============================] - 236s 1s/step - loss: 0.3906 - val_loss: 0.0713\n",
            "Epoch 2/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 0.0174 - val_loss: 0.0028\n",
            "Epoch 3/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 0.0011 - val_loss: 0.0000e+00\n",
            "Epoch 4/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 3.7599e-05 - val_loss: 0.0000e+00\n",
            "Epoch 5/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 1.7569e-06 - val_loss: 0.0000e+00\n",
            "Epoch 6/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 7.1774e-06 - val_loss: 0.0000e+00\n",
            "Epoch 7/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 8.1974e-07 - val_loss: 0.0000e+00\n",
            "Epoch 8/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 1.2569e-06 - val_loss: 0.0000e+00\n",
            "Epoch 00008: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SVFdstOXEgG",
        "colab_type": "code",
        "outputId": "962cd151-6056-4b40-e38b-5af8f223067e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "TrainModel(Ind_DB,\"Black Rhino\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "Training for Species:  Black Rhino\n",
            "Epoch 1/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 0.2464 - val_loss: 0.0299\n",
            "Epoch 2/30\n",
            "200/200 [==============================] - 233s 1s/step - loss: 0.0104 - val_loss: 0.0000e+00\n",
            "Epoch 3/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 3.3095e-05 - val_loss: 0.0000e+00\n",
            "Epoch 4/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 3.6925e-06 - val_loss: 0.0000e+00\n",
            "Epoch 5/30\n",
            "200/200 [==============================] - 233s 1s/step - loss: 0.0093 - val_loss: 0.0220\n",
            "Epoch 6/30\n",
            "200/200 [==============================] - 233s 1s/step - loss: 0.0034 - val_loss: 0.0000e+00\n",
            "Epoch 7/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 1.5673e-05 - val_loss: 0.0000e+00\n",
            "Epoch 00007: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BoPgcuVXL3M",
        "colab_type": "code",
        "outputId": "88ca9a67-8202-47ac-d85d-d42c2e43be0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "TrainModel(Ind_DB,\"Cheetah\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "Training for Species:  Cheetah\n",
            "Epoch 1/30\n",
            "200/200 [==============================] - 235s 1s/step - loss: 0.5401 - val_loss: 0.2910\n",
            "Epoch 2/30\n",
            "200/200 [==============================] - 235s 1s/step - loss: 0.2578 - val_loss: 0.2071\n",
            "Epoch 3/30\n",
            "200/200 [==============================] - 235s 1s/step - loss: 0.1866 - val_loss: 0.1216\n",
            "Epoch 4/30\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0919"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8GTkanSpRYE",
        "colab_type": "code",
        "outputId": "48aa55db-a7e6-4ec7-c786-947f8ff62d14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "TrainModel(Ind_DB,'Leopard')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "Training for Species:  Leopard\n",
            "Epoch 1/30\n",
            "200/200 [==============================] - 235s 1s/step - loss: 0.3450 - val_loss: 0.1621\n",
            "Epoch 2/30\n",
            "200/200 [==============================] - 233s 1s/step - loss: 0.0435 - val_loss: 0.0029\n",
            "Epoch 3/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 0.0034 - val_loss: 8.0740e-04\n",
            "Epoch 4/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 6.4314e-04 - val_loss: 0.0000e+00\n",
            "Epoch 5/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 1.4803e-04 - val_loss: 0.0000e+00\n",
            "Epoch 6/30\n",
            "200/200 [==============================] - 235s 1s/step - loss: 0.0200 - val_loss: 0.0000e+00\n",
            "Epoch 7/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 3.9069e-05 - val_loss: 0.0000e+00\n",
            "Epoch 8/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 1.2779e-04 - val_loss: 0.0000e+00\n",
            "Epoch 9/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Epoch 00009: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwDpxeM4XOpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TrainModel(Ind_DB,\"Lowland Tapir\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5cUR1gaXR8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TrainModel(Ind_DB,\"Puma\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVAX9QrMXVc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TrainModel(Ind_DB,\"White Rhino\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtGbtYNEl44C",
        "colab_type": "code",
        "outputId": "394fa9bb-5bec-4dc8-f807-5d161b152120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "TrainModel(Ind_DB,\"Bongo\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "Training for Species:  Bongo\n",
            "Epoch 1/30\n",
            "200/200 [==============================] - 233s 1s/step - loss: 0.3604 - val_loss: 0.1240\n",
            "Epoch 2/30\n",
            "200/200 [==============================] - 233s 1s/step - loss: 0.1201 - val_loss: 0.0603\n",
            "Epoch 3/30\n",
            "200/200 [==============================] - 233s 1s/step - loss: 0.0283 - val_loss: 0.0000e+00\n",
            "Epoch 4/30\n",
            "200/200 [==============================] - 233s 1s/step - loss: 4.4315e-04 - val_loss: 0.0000e+00\n",
            "Epoch 5/30\n",
            "200/200 [==============================] - 233s 1s/step - loss: 8.5387e-05 - val_loss: 0.0000e+00\n",
            "Epoch 6/30\n",
            "200/200 [==============================] - 233s 1s/step - loss: 4.7711e-05 - val_loss: 0.0000e+00\n",
            "Epoch 7/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 4.7742e-05 - val_loss: 0.0000e+00\n",
            "Epoch 8/30\n",
            "200/200 [==============================] - 233s 1s/step - loss: 6.7269e-05 - val_loss: 0.0000e+00\n",
            "Epoch 00008: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FVmTvmTl6zf",
        "colab_type": "code",
        "outputId": "a12c2da4-fb8d-49cf-e04b-d18447f571d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "TrainModel(Ind_DB,\"African elephant\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "Training for Species:  African elephant\n",
            "Epoch 1/30\n",
            "200/200 [==============================] - 233s 1s/step - loss: 0.4228 - val_loss: 0.1040\n",
            "Epoch 2/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 0.0591 - val_loss: 0.0174\n",
            "Epoch 3/30\n",
            "200/200 [==============================] - 233s 1s/step - loss: 0.0124 - val_loss: 0.0087\n",
            "Epoch 4/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 0.0045 - val_loss: 0.0000e+00\n",
            "Epoch 5/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 1.2377e-04 - val_loss: 0.0000e+00\n",
            "Epoch 6/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 4.1661e-05 - val_loss: 0.0000e+00\n",
            "Epoch 7/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 1.1775e-04 - val_loss: 0.0000e+00\n",
            "Epoch 8/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 6.8500e-05 - val_loss: 0.0000e+00\n",
            "Epoch 9/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 2.2661e-05 - val_loss: 0.0000e+00\n",
            "Epoch 00009: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrIGitwtl9gE",
        "colab_type": "code",
        "outputId": "85ec0d2f-8462-402e-84cc-9b8282d11896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "TrainModel(Ind_DB,\"African lion\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "Training for Species:  African lion\n",
            "Epoch 1/30\n",
            "200/200 [==============================] - 233s 1s/step - loss: 0.4974 - val_loss: 0.2235\n",
            "Epoch 2/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 0.1424 - val_loss: 0.0426\n",
            "Epoch 3/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 0.0345 - val_loss: 0.0041\n",
            "Epoch 4/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 0.0068 - val_loss: 0.0034\n",
            "Epoch 5/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 0.0030 - val_loss: 0.0000e+00\n",
            "Epoch 6/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 1.9447e-04 - val_loss: 0.0000e+00\n",
            "Epoch 7/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 1.3984e-04 - val_loss: 0.0000e+00\n",
            "Epoch 8/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 4.0202e-05 - val_loss: 0.0000e+00\n",
            "Epoch 9/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 2.0741e-05 - val_loss: 0.0000e+00\n",
            "Epoch 10/30\n",
            "200/200 [==============================] - 234s 1s/step - loss: 2.9253e-05 - val_loss: 0.0000e+00\n",
            "Epoch 00010: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNIF0cjNbT2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}