{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "WildAI_Individual_Identification_Siamese.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KYR7pbX14X4",
        "colab_type": "text"
      },
      "source": [
        "# Individual Identification Model Using Siamese Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EjpS3ALNGXp",
        "colab_type": "text"
      },
      "source": [
        "## 1. Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FisML2XKeQoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "-HnFnM3O14X-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam, Adamax\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input as VGG16Pre\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.applications.xception import preprocess_input as XceptionPre\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as MNPre"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpC1yQZ1eGMm",
        "colab_type": "code",
        "outputId": "41b837bf-19e5-469b-bc2f-c35a2f8a6702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Mount Google Drive - Note this mounts your personal Google Drive to the directory stated\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nsb8nrZwhPQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up the location of the dataset to work with\n",
        "path = os.path.join('/content/drive/My Drive/U C Berkeley - Darragh/')\n",
        "train_path = os.path.join(path,'Training Data')\n",
        "test_path = os.path.join(path,'Test Data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSDlX-56NsWH",
        "colab_type": "text"
      },
      "source": [
        "## 2. Custom Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXMCgEOQPAmd",
        "colab_type": "text"
      },
      "source": [
        "### 2-1. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yd6i5dXNwMD",
        "colab_type": "text"
      },
      "source": [
        "#### 2-1-1. Data Load\n",
        "The following code loads all the images from the given path passed through the parameter `path` so that any dataset can be easily extracted by altering the parameter.\n",
        "\n",
        "All the images are changed to grayscale, resized, converted to an array, and all the arrays of the images that belong to the same class of individuals are saved under the same key value in a dictionary, where the key value is a name of an individual (concatenation of species and individual names), and the values are a list of all the arrays of the images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojYFZ4c1hQwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loads all the images grouped by individuals from the given directory path\n",
        "def loadimgs(path):\n",
        "    total_individuals = 1\n",
        "    species_list = []\n",
        "    data_dict = {}\n",
        "\n",
        "    for species in os.listdir(path):\n",
        "        species_list.append(species)\n",
        "        print(\"loading species: \" + species)\n",
        "        species_path = os.path.join(path,species)\n",
        "        for individual in os.listdir(species_path):\n",
        "            individual_path = os.path.join(species_path, individual)            \n",
        "            for filename in os.listdir(individual_path):\n",
        "                image_path = os.path.join(individual_path, filename)\n",
        "                image = cv2.imread(image_path)\n",
        "                if image is not None:\n",
        "                  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "                  resized_image=cv2.resize(gray,(92,112),interpolation = cv2.INTER_AREA)\n",
        "                  array_1d = np.asarray(resized_image)\n",
        "                  if species+'-'+individual not in data_dict:\n",
        "                    data_dict[species+'-'+individual] = []\n",
        "                  data_dict[species+'-'+individual].append(array_1d)\n",
        "                  total_individuals += 1\n",
        "    return total_individuals, data_dict, species_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_i7ZSnYjNQS",
        "colab_type": "code",
        "outputId": "1cbd1b98-1113-4523-ed17-ca63f3d609c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "# Loads both train and test dataset\n",
        "print(\"---Loading Training Data...---\")\n",
        "train_size, train_data, train_species = loadimgs(train_path)\n",
        "print(\"---Loading Test Data...---\")\n",
        "test_size, test_data, test_species = loadimgs(test_path)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---Loading Training Data...---\n",
            "loading species: Amur Tiger\n",
            "loading species: Bengal Tiger\n",
            "loading species: Cheetah\n",
            "loading species: Leopard\n",
            "loading species: Lowland Tapir\n",
            "loading species: Puma\n",
            "loading species: White Rhino\n",
            "loading species: Black Rhino\n",
            "loading species: African lion\n",
            "loading species: African elephant\n",
            "loading species: Bongo\n",
            "---Loading Test Data...---\n",
            "loading species: Amur Tiger\n",
            "loading species: Bengal Tiger\n",
            "loading species: Cheetah\n",
            "loading species: Leopard\n",
            "loading species: Lowland Tapir\n",
            "loading species: Puma\n",
            "loading species: White Rhino\n",
            "loading species: Black Rhino\n",
            "loading species: African lion\n",
            "loading species: African elephant\n",
            "loading species: Bongo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d3VIG9F14Yp",
        "colab_type": "text"
      },
      "source": [
        "In the following cells, a simple code is implemented to grasp a high-level understanding on the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHtVzs4314Yq",
        "colab_type": "code",
        "outputId": "bd503716-5d07-4e82-ffaf-d1ccfa9c1c56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Train & Test data size\n",
        "print(\"Training data size: \",train_size)\n",
        "print(\"Test data size: \",test_size)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data size:  1724\n",
            "Test data size:  205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N07LODN2Y2ah",
        "colab_type": "code",
        "outputId": "52882143-0858-4e4f-91e0-89b876414801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Number of species classes\n",
        "print(\"Total number of species: \", len(train_species))\n",
        "print(train_species)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of species:  11\n",
            "['Amur Tiger', 'Bengal Tiger', 'Cheetah', 'Leopard', 'Lowland Tapir', 'Puma', 'White Rhino', 'Black Rhino', 'African lion', 'African elephant', 'Bongo']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg8iAJyhwoNs",
        "colab_type": "code",
        "outputId": "de531319-1cf2-4eb8-9ae6-1f00d5c5a7d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Number of individual classes\n",
        "print(\"Total number of classes: \", len(train_data.keys()))\n",
        "print(train_data.keys())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of classes:  98\n",
            "dict_keys(['Amur Tiger-261', 'Amur Tiger-237', 'Amur Tiger-279', 'Amur Tiger-440', 'Amur Tiger-565', 'Amur Tiger-682', 'Amur Tiger-1020', 'Bengal Tiger-Aria', 'Bengal Tiger-Fenimore', 'Bengal Tiger-India', 'Bengal Tiger-Lucky', 'Bengal Tiger-Moki', 'Bengal Tiger-Mona', 'Bengal Tiger-Rajah', 'Bengal Tiger-Rajaji', 'Cheetah-Aiko', 'Cheetah-Alvin', 'Cheetah-Chiquita', 'Cheetah-Jamu', 'Cheetah-Kiki', 'Cheetah-Pano', 'Cheetah-Rusty', 'Cheetah-Sandy', 'Cheetah-Tearmark', 'Leopard-Keanu', 'Leopard-Lewa', 'Leopard-Mick', 'Leopard-Ombeli', 'Leopard-Timbila', 'Leopard-Tony', 'Leopard-Wahoo', 'Leopard-Shakira', 'Lowland Tapir-Sorocaba 2', 'Lowland Tapir-Chuva F', 'Lowland Tapir-Sorocaba 5', 'Lowland Tapir-Edinha F', 'Lowland Tapir-Feminha F', 'Lowland Tapir-Pistolinha M', 'Lowland Tapir-Sorocaba', 'Lowland Tapir-Chuvisco M', 'Lowland Tapir-Riscado M', 'Puma-M-Taz', 'Puma-M-Skit', 'Puma-M-Pops', 'Puma-M-Phoenix', 'Puma-M-Oldex', 'Puma-M-Juvboy', 'Puma-M-Darby', 'Puma-F-Tawny', 'Puma-F-Spots', 'Puma-F-Majanna', 'Puma-F-Lip', 'Puma-F-Cassie', 'Puma-F-Archback', 'White Rhino-Kalakwa Cs10', 'White Rhino-Kalakwa Cs5', 'White Rhino-Kalakwa Cs15', 'White Rhino-Kalakwa Cs6', 'White Rhino-Kal Cs 9JunKML3', 'White Rhino-Kal Cs 6JunKML2', 'White Rhino-Kalakwa Cs7', 'White Rhino-Kalakwa Cs17', 'Black Rhino-Kal Db Himb', 'Black Rhino-Kal Db Jav', 'Black Rhino-Kal Db Kuz', 'Black Rhino-Kal Db M1', 'Black Rhino-Kal Db M2', 'Black Rhino-Kuz Db Col', 'Black Rhino-Kuz Db Hec', 'Black Rhino-Kuz Db Hel', 'Black Rhino-Kuz Db Ken', 'African lion-Jamu', 'African lion-Mogli', 'African lion-Ceasar', 'African lion-Maro', 'African lion-Jan', 'African lion-Elsa', 'African lion-Inca', 'African lion-Elangeny', 'African lion-Mapivu', 'African lion-Bijan', 'African elephant-Mashudu', 'African elephant-Abu', 'African elephant-Thandi', 'African elephant-Chikenya', 'African elephant-Lorato', 'African elephant-Sukeri', 'African elephant-Sene', 'African elephant-Thato', 'African elephant-Paseka', 'Bongo-Rehema', 'Bongo-Lucy', 'Bongo-Kalama', 'Bongo-Nolano', 'Bongo-Bambi', 'Bongo-Malaika', 'Bongo-Nengese', 'Bongo-Amani'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spOAElrs14Y2",
        "colab_type": "code",
        "outputId": "e935a780-651d-40ef-9020-aa9d2cadf3cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Size of an array of one sample image\n",
        "train_data[\"Amur Tiger-261\"][0].shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(112, 92)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At4Ahhoo14Y5",
        "colab_type": "text"
      },
      "source": [
        "#### 2-1-2. Generating Training Dataset\n",
        "The following function `get_data` generates an input data to be fed into the Siamese network later. \n",
        "\n",
        "The key concept of the Siamese network is that a model predicts whether or not two given input images belong to the same class. In order to train the model, both images of the same class and different classes need to be given so that the model can differentiate different characteristics between classes.\n",
        "\n",
        "The function `get_data` exists for that reason. It generates the same number of same individual pairs(denoted by `x_genuine_pair`) and different individual pairs(denoted by `x_imposite_pair`). It also generates the corresponding binary labels - 0 if the two images are from two different individuals; 1 if the two images are from the same individual.\n",
        "\n",
        "I would like to note that the pairs of images are extracted from the same species as the individual identification model will use the predicted species from the species classification model as one of its input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGrQoWdgTLZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(size, total_sample_size, dataset):\n",
        "  image = dataset[\"Amur Tiger-261\"][0]\n",
        "  image = image[::size, ::size]\n",
        "  dim1 = image.shape[0]\n",
        "  dim2 = image.shape[1]\n",
        "    \n",
        "  # Initialize the numpy array with the shape of [total_sample, no_of_pairs, dim1, dim2]\n",
        "  x_genuine_pair = np.zeros([total_sample_size, 2, 1, dim1, dim2])  # 2 is for pairs\n",
        "  y_genuine = np.zeros([total_sample_size, 1])\n",
        "\n",
        "  x_imposite_pair = np.zeros([total_sample_size, 2, 1, dim1, dim2])\n",
        "  y_imposite = np.zeros([total_sample_size, 1])\n",
        "\n",
        "  species_dict = {}\n",
        "  individuals = list(dataset.keys())\n",
        "\n",
        "  # Generates all possible pairs of the two images within the same species\n",
        "  for species in train_species:\n",
        "\n",
        "    # Filter only individuals within the same species\n",
        "    individuals_new = [ind for ind in individuals if ind.find(species) != -1]\n",
        "    #print(species, individuals_new)\n",
        "\n",
        "    # Same individual pairs\n",
        "    count1 = 0\n",
        "    print(\"Generating same individual pairs for \"+species)\n",
        "    for ind in individuals_new:\n",
        "      footprints = dataset[ind]\n",
        "      max_idx = len(footprints) - 1\n",
        "      for idx, img in enumerate(footprints):\n",
        "        counter = idx + 1\n",
        "        while counter <= max_idx:\n",
        "          img1 = img\n",
        "          img2 = footprints[counter]\n",
        "          # Reduce the size\n",
        "          img1 = img1[::size, ::size]\n",
        "          img2 = img2[::size, ::size]\n",
        "          # Store the images to the initialized numpy array\n",
        "          x_genuine_pair[count1, 0, 0, :, :] = img1\n",
        "          x_genuine_pair[count1, 1, 0, :, :] = img2\n",
        "          # Assign the label as one as we are drawing images from the same individual (genuine pair)\n",
        "          y_genuine[count1] = 1\n",
        "          counter += 1\n",
        "          count1 += 1\n",
        "\n",
        "    # Different individual pairs\n",
        "    count2 = 0\n",
        "    print(\"Generating different individual pairs for \"+species)\n",
        "    for idx, img in enumerate(individuals_new[:-1]):\n",
        "      ind1 = individuals_new[idx]\n",
        "      footprints1 = dataset[ind1]\n",
        "      ind2_list = individuals_new[idx+1:]\n",
        "      for idx2, img2 in enumerate(ind2_list):\n",
        "        ind2 = ind2_list[idx2]\n",
        "        footprints2 = dataset[ind2]\n",
        "        #print(ind1, ind2)\n",
        "        for fp1 in footprints1:\n",
        "          for fp2 in footprints2:\n",
        "            img1 = fp1\n",
        "            img2 = fp2\n",
        "            # Reduce the size\n",
        "            img1 = img1[::size, ::size]\n",
        "            img2 = img2[::size, ::size]\n",
        "            # Store the images to the initialized numpy array\n",
        "            x_imposite_pair[count2, 0, 0, :, :] = img1\n",
        "            x_imposite_pair[count2, 1, 0, :, :] = img2\n",
        "            # Assign the label as zero as we are drawing images from different individuals\n",
        "            y_imposite[count2] = 0\n",
        "            count2 += 1\n",
        "  \n",
        "  # Generate the SAME NUMBER of pairs for two target classes (0: different individuals, 1: same individuals)\n",
        "  count = min(count1, count2)\n",
        "\n",
        "  x_genuine_pair_new = np.zeros([count, 2, 1, dim1, dim2])  # 2 is for pairs\n",
        "  y_genuine_new = np.zeros([count, 1])\n",
        "\n",
        "  x_imposite_pair_new = np.zeros([count, 2, 1, dim1, dim2])\n",
        "  y_imposite_new = np.zeros([count, 1])\n",
        "\n",
        "  genuine_idx = np.random.choice(range(count1), count, replace=False)\n",
        "  imposite_idx = np.random.choice(range(count2), count, replace=False)\n",
        "\n",
        "  for idx1, idx2, counter in zip(genuine_idx, imposite_idx, range(count)):\n",
        "    x_genuine_pair_new[counter, 0, 0, :, :] = x_genuine_pair[idx1, 0, 0, :, :]\n",
        "    x_genuine_pair_new[counter, 1, 0, :, :] = x_genuine_pair[idx1, 1, 0, :, :]\n",
        "    y_genuine_new[counter] = 1\n",
        "\n",
        "    x_imposite_pair_new[counter, 0, 0, :, :] = x_imposite_pair[idx2, 0, 0, :, :]\n",
        "    x_imposite_pair_new[counter, 1, 0, :, :] = x_imposite_pair[idx2, 1, 0, :, :]\n",
        "    y_imposite_new[counter] = 0\n",
        "\n",
        "  # Concatenate genuine pairs and imposite pairs to get the whole dataset\n",
        "  X = np.concatenate([x_genuine_pair_new, x_imposite_pair_new], axis=0)/255\n",
        "  Y = np.concatenate([y_genuine_new, y_imposite_new], axis=0)\n",
        "  print(\"The End\")\n",
        "  return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIeV7c3v94E8",
        "colab_type": "code",
        "outputId": "903e4378-d9b8-4bfe-d4a4-ae1d506b0915",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "size = 2\n",
        "total_sample_size = 50000\n",
        "X, Y = get_data(size, total_sample_size, train_data)\n",
        "print(len(X), len(Y))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating same individual pairs for Amur Tiger\n",
            "Generating different individual pairs for Amur Tiger\n",
            "Generating same individual pairs for Bengal Tiger\n",
            "Generating different individual pairs for Bengal Tiger\n",
            "Generating same individual pairs for Cheetah\n",
            "Generating different individual pairs for Cheetah\n",
            "Generating same individual pairs for Leopard\n",
            "Generating different individual pairs for Leopard\n",
            "Generating same individual pairs for Lowland Tapir\n",
            "Generating different individual pairs for Lowland Tapir\n",
            "Generating same individual pairs for Puma\n",
            "Generating different individual pairs for Puma\n",
            "Generating same individual pairs for White Rhino\n",
            "Generating different individual pairs for White Rhino\n",
            "Generating same individual pairs for Black Rhino\n",
            "Generating different individual pairs for Black Rhino\n",
            "Generating same individual pairs for African lion\n",
            "Generating different individual pairs for African lion\n",
            "Generating same individual pairs for African elephant\n",
            "Generating different individual pairs for African elephant\n",
            "Generating same individual pairs for Bongo\n",
            "Generating different individual pairs for Bongo\n",
            "The End\n",
            "796 796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRFWV0UWWN7W",
        "colab_type": "text"
      },
      "source": [
        "#### 2-1-3. Data Split\n",
        "The final step in data preprocessing before the modeling is to split the dataset into train and test(validation) dataset. 75:25 data split ratio is applied to the dataset - 75% of the dataset is used to train the model, and the remaining 25% is used to validate the model in the end."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBV4ROy_-aj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KdSHziM14ZB",
        "colab_type": "code",
        "outputId": "68bb9604-9afd-4d15-c16f-1a809de2b4ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(597, 2, 1, 56, 46)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7o7lnymL14ZD",
        "colab_type": "code",
        "outputId": "21831d0e-a68a-40f6-e3a6-31e4d71f580b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(597, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOEsXCLiSx-p",
        "colab_type": "code",
        "outputId": "cd732ae2-2e56-4fd8-db50-14672c8f40fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(199, 2, 1, 56, 46)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5VTBbNcSxvJ",
        "colab_type": "code",
        "outputId": "24e14cfb-f5c4-4f6c-9a2f-2fcaae38afab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(199, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5W9jtdoWgR1",
        "colab_type": "text"
      },
      "source": [
        "### 2-2. Model Development"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aQp4MQHWjH1",
        "colab_type": "text"
      },
      "source": [
        "#### 2-2-1. Base Model\n",
        "In the following code, a base Siamese network model is built. The model is composed of two convolutional layers with rectified linear unit (ReLU) activations and maxpooling followed by a flat layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjNqh2RQ14ZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_base_network(input_shape):\n",
        "  seq = Sequential()\n",
        "    \n",
        "  nb_filter = [6, 12]\n",
        "  kernel_size = 3\n",
        "    \n",
        "  # Convolutional layer 1\n",
        "  seq.add(Convolution2D(nb_filter[0], kernel_size, kernel_size, input_shape=input_shape, padding='valid', data_format=\"channels_first\")) #NHWC\n",
        "  seq.add(Activation('relu'))\n",
        "  seq.add(MaxPooling2D(pool_size=(2, 2)))  \n",
        "  seq.add(Dropout(.25))\n",
        "    \n",
        "  # Convolutional layer 2\n",
        "  seq.add(Convolution2D(nb_filter[1], kernel_size, kernel_size, padding='valid', data_format=\"channels_first\"))\n",
        "  seq.add(Activation('relu'))\n",
        "  seq.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")) # Keras1 > dim_ordering='th'\n",
        "  seq.add(Dropout(.25))\n",
        "\n",
        "  # Flatten \n",
        "  seq.add(Flatten())\n",
        "  seq.add(Dense(128, activation='relu'))\n",
        "  seq.add(Dropout(0.1))\n",
        "  seq.add(Dense(50, activation='relu'))\n",
        "\n",
        "  seq.summary()\n",
        "  \n",
        "  return seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIwKsH9714ZQ",
        "colab_type": "text"
      },
      "source": [
        "Next, the image pairs are fed into the base network, which returns embeddings, that is, feature vectors - `feat_vecs_a` and `feat_vecs_b`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd9Vsfbl14ZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = x_train.shape[2:]\n",
        "img_a = Input(shape=input_dim)\n",
        "img_b = Input(shape=input_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmWkKX3IThXi",
        "colab_type": "code",
        "outputId": "d7938878-3281-4a9e-f9ad-1f375074b4e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(input_dim)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 56, 46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ-cUoYY14ZS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "3707abb4-ae3a-4a6e-8256-c2a268d04f94"
      },
      "source": [
        "base_network = build_base_network(input_dim)\n",
        "feat_vecs_a = base_network(img_a)\n",
        "feat_vecs_b = base_network(img_b)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 6, 18, 15)         60        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 6, 18, 15)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 3, 9, 15)          0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 3, 9, 15)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 12, 3, 5)          336       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 12, 3, 5)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 1, 2)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 1, 2)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 24)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               3200      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50)                6450      \n",
            "=================================================================\n",
            "Total params: 10,046\n",
            "Trainable params: 10,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo53CEECZo_F",
        "colab_type": "text"
      },
      "source": [
        "#### 2-2-2. Model Training\n",
        "The following code trains the base model defined above with the optimal hyperparameters that were identified in our multiple trials. Some examples of the hyperparameters that were altered to enhance the model are optimizer, loss function, and number of epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37zSqQ9p14ZW",
        "colab_type": "text"
      },
      "source": [
        "The feature vectors from the base model are passed to the energy function to compute the distance between them, which uses Euclidean distance as a function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwjDjq1L14ZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def euclidean_distance(vects):\n",
        "    x, y = vects\n",
        "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
        "\n",
        "def eucl_dist_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYMD3Hbz14ZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([feat_vecs_a, feat_vecs_b])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUTmqA8514Zf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up number of epochs and optimizer for our model\n",
        "epochs = 200\n",
        "optimizer = Adam(0.005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdZPO0Ld14Zh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=[img_a, img_b], outputs=distance)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J906laLp14Zj",
        "colab_type": "text"
      },
      "source": [
        "Next, `contrastive_loss` function is defined to be used as the loss function of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7Lu8sQo14Zk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def contrastive_loss(y_true, y_pred):\n",
        "    margin = 1\n",
        "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtEVqf1D14Zn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=contrastive_loss, optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n7Ivffo14Zp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_1 = x_train[:, 0]\n",
        "img_2 = x_train[:, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdrU93W814Zr",
        "colab_type": "code",
        "outputId": "e4002c5c-0446-455c-8008-5c00ed4369f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit([img_1, img_2], y_train, validation_split=.25, batch_size=64, verbose=2, epochs=epochs)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "7/7 - 0s - loss: 0.2644 - val_loss: 0.4131\n",
            "Epoch 2/200\n",
            "7/7 - 0s - loss: 0.2613 - val_loss: 0.4221\n",
            "Epoch 3/200\n",
            "7/7 - 0s - loss: 0.2600 - val_loss: 0.4023\n",
            "Epoch 4/200\n",
            "7/7 - 0s - loss: 0.2585 - val_loss: 0.3963\n",
            "Epoch 5/200\n",
            "7/7 - 0s - loss: 0.2581 - val_loss: 0.3901\n",
            "Epoch 6/200\n",
            "7/7 - 0s - loss: 0.2576 - val_loss: 0.3851\n",
            "Epoch 7/200\n",
            "7/7 - 0s - loss: 0.2579 - val_loss: 0.3824\n",
            "Epoch 8/200\n",
            "7/7 - 0s - loss: 0.2580 - val_loss: 0.3658\n",
            "Epoch 9/200\n",
            "7/7 - 0s - loss: 0.2486 - val_loss: 0.3599\n",
            "Epoch 10/200\n",
            "7/7 - 0s - loss: 0.2461 - val_loss: 0.3404\n",
            "Epoch 11/200\n",
            "7/7 - 0s - loss: 0.2527 - val_loss: 0.3435\n",
            "Epoch 12/200\n",
            "7/7 - 0s - loss: 0.2493 - val_loss: 0.3175\n",
            "Epoch 13/200\n",
            "7/7 - 0s - loss: 0.2548 - val_loss: 0.3216\n",
            "Epoch 14/200\n",
            "7/7 - 0s - loss: 0.2468 - val_loss: 0.3174\n",
            "Epoch 15/200\n",
            "7/7 - 0s - loss: 0.2391 - val_loss: 0.2925\n",
            "Epoch 16/200\n",
            "7/7 - 0s - loss: 0.2284 - val_loss: 0.2872\n",
            "Epoch 17/200\n",
            "7/7 - 0s - loss: 0.2254 - val_loss: 0.2745\n",
            "Epoch 18/200\n",
            "7/7 - 0s - loss: 0.2229 - val_loss: 0.2484\n",
            "Epoch 19/200\n",
            "7/7 - 0s - loss: 0.2358 - val_loss: 0.2784\n",
            "Epoch 20/200\n",
            "7/7 - 0s - loss: 0.2202 - val_loss: 0.2434\n",
            "Epoch 21/200\n",
            "7/7 - 0s - loss: 0.2195 - val_loss: 0.2392\n",
            "Epoch 22/200\n",
            "7/7 - 0s - loss: 0.2151 - val_loss: 0.2358\n",
            "Epoch 23/200\n",
            "7/7 - 0s - loss: 0.2119 - val_loss: 0.2309\n",
            "Epoch 24/200\n",
            "7/7 - 0s - loss: 0.2034 - val_loss: 0.2290\n",
            "Epoch 25/200\n",
            "7/7 - 0s - loss: 0.2048 - val_loss: 0.2349\n",
            "Epoch 26/200\n",
            "7/7 - 0s - loss: 0.2137 - val_loss: 0.2370\n",
            "Epoch 27/200\n",
            "7/7 - 0s - loss: 0.2202 - val_loss: 0.2576\n",
            "Epoch 28/200\n",
            "7/7 - 0s - loss: 0.2141 - val_loss: 0.2324\n",
            "Epoch 29/200\n",
            "7/7 - 0s - loss: 0.1980 - val_loss: 0.2244\n",
            "Epoch 30/200\n",
            "7/7 - 0s - loss: 0.1969 - val_loss: 0.2307\n",
            "Epoch 31/200\n",
            "7/7 - 0s - loss: 0.1947 - val_loss: 0.2449\n",
            "Epoch 32/200\n",
            "7/7 - 0s - loss: 0.1927 - val_loss: 0.2264\n",
            "Epoch 33/200\n",
            "7/7 - 0s - loss: 0.1940 - val_loss: 0.2241\n",
            "Epoch 34/200\n",
            "7/7 - 0s - loss: 0.1926 - val_loss: 0.2253\n",
            "Epoch 35/200\n",
            "7/7 - 0s - loss: 0.1887 - val_loss: 0.2238\n",
            "Epoch 36/200\n",
            "7/7 - 0s - loss: 0.1884 - val_loss: 0.2183\n",
            "Epoch 37/200\n",
            "7/7 - 0s - loss: 0.1873 - val_loss: 0.2234\n",
            "Epoch 38/200\n",
            "7/7 - 0s - loss: 0.1881 - val_loss: 0.2246\n",
            "Epoch 39/200\n",
            "7/7 - 0s - loss: 0.1963 - val_loss: 0.2305\n",
            "Epoch 40/200\n",
            "7/7 - 0s - loss: 0.1934 - val_loss: 0.2325\n",
            "Epoch 41/200\n",
            "7/7 - 0s - loss: 0.1964 - val_loss: 0.2367\n",
            "Epoch 42/200\n",
            "7/7 - 0s - loss: 0.2029 - val_loss: 0.2291\n",
            "Epoch 43/200\n",
            "7/7 - 0s - loss: 0.1827 - val_loss: 0.2259\n",
            "Epoch 44/200\n",
            "7/7 - 0s - loss: 0.2006 - val_loss: 0.2403\n",
            "Epoch 45/200\n",
            "7/7 - 0s - loss: 0.1940 - val_loss: 0.2190\n",
            "Epoch 46/200\n",
            "7/7 - 0s - loss: 0.1870 - val_loss: 0.2174\n",
            "Epoch 47/200\n",
            "7/7 - 0s - loss: 0.1839 - val_loss: 0.2153\n",
            "Epoch 48/200\n",
            "7/7 - 0s - loss: 0.1860 - val_loss: 0.2125\n",
            "Epoch 49/200\n",
            "7/7 - 0s - loss: 0.1804 - val_loss: 0.2181\n",
            "Epoch 50/200\n",
            "7/7 - 0s - loss: 0.1862 - val_loss: 0.2190\n",
            "Epoch 51/200\n",
            "7/7 - 0s - loss: 0.1797 - val_loss: 0.2197\n",
            "Epoch 52/200\n",
            "7/7 - 0s - loss: 0.1756 - val_loss: 0.2107\n",
            "Epoch 53/200\n",
            "7/7 - 0s - loss: 0.1788 - val_loss: 0.2119\n",
            "Epoch 54/200\n",
            "7/7 - 0s - loss: 0.1728 - val_loss: 0.2114\n",
            "Epoch 55/200\n",
            "7/7 - 0s - loss: 0.1810 - val_loss: 0.2246\n",
            "Epoch 56/200\n",
            "7/7 - 0s - loss: 0.1846 - val_loss: 0.2196\n",
            "Epoch 57/200\n",
            "7/7 - 0s - loss: 0.1810 - val_loss: 0.2108\n",
            "Epoch 58/200\n",
            "7/7 - 0s - loss: 0.1829 - val_loss: 0.2307\n",
            "Epoch 59/200\n",
            "7/7 - 0s - loss: 0.1905 - val_loss: 0.2309\n",
            "Epoch 60/200\n",
            "7/7 - 0s - loss: 0.1829 - val_loss: 0.2304\n",
            "Epoch 61/200\n",
            "7/7 - 0s - loss: 0.1903 - val_loss: 0.2230\n",
            "Epoch 62/200\n",
            "7/7 - 0s - loss: 0.1796 - val_loss: 0.2251\n",
            "Epoch 63/200\n",
            "7/7 - 0s - loss: 0.1856 - val_loss: 0.2221\n",
            "Epoch 64/200\n",
            "7/7 - 0s - loss: 0.1770 - val_loss: 0.2150\n",
            "Epoch 65/200\n",
            "7/7 - 0s - loss: 0.1806 - val_loss: 0.2308\n",
            "Epoch 66/200\n",
            "7/7 - 0s - loss: 0.1808 - val_loss: 0.2229\n",
            "Epoch 67/200\n",
            "7/7 - 0s - loss: 0.1768 - val_loss: 0.2157\n",
            "Epoch 68/200\n",
            "7/7 - 0s - loss: 0.1748 - val_loss: 0.2138\n",
            "Epoch 69/200\n",
            "7/7 - 0s - loss: 0.1755 - val_loss: 0.2146\n",
            "Epoch 70/200\n",
            "7/7 - 0s - loss: 0.1768 - val_loss: 0.2097\n",
            "Epoch 71/200\n",
            "7/7 - 0s - loss: 0.1711 - val_loss: 0.2130\n",
            "Epoch 72/200\n",
            "7/7 - 0s - loss: 0.1704 - val_loss: 0.2029\n",
            "Epoch 73/200\n",
            "7/7 - 0s - loss: 0.1708 - val_loss: 0.2037\n",
            "Epoch 74/200\n",
            "7/7 - 0s - loss: 0.1625 - val_loss: 0.2016\n",
            "Epoch 75/200\n",
            "7/7 - 0s - loss: 0.1683 - val_loss: 0.2008\n",
            "Epoch 76/200\n",
            "7/7 - 0s - loss: 0.1754 - val_loss: 0.2046\n",
            "Epoch 77/200\n",
            "7/7 - 0s - loss: 0.1692 - val_loss: 0.2057\n",
            "Epoch 78/200\n",
            "7/7 - 0s - loss: 0.1603 - val_loss: 0.1967\n",
            "Epoch 79/200\n",
            "7/7 - 0s - loss: 0.1690 - val_loss: 0.1958\n",
            "Epoch 80/200\n",
            "7/7 - 0s - loss: 0.1795 - val_loss: 0.2170\n",
            "Epoch 81/200\n",
            "7/7 - 0s - loss: 0.1641 - val_loss: 0.2030\n",
            "Epoch 82/200\n",
            "7/7 - 0s - loss: 0.1693 - val_loss: 0.1956\n",
            "Epoch 83/200\n",
            "7/7 - 0s - loss: 0.1736 - val_loss: 0.2044\n",
            "Epoch 84/200\n",
            "7/7 - 0s - loss: 0.1660 - val_loss: 0.1986\n",
            "Epoch 85/200\n",
            "7/7 - 0s - loss: 0.1652 - val_loss: 0.2016\n",
            "Epoch 86/200\n",
            "7/7 - 0s - loss: 0.1698 - val_loss: 0.1983\n",
            "Epoch 87/200\n",
            "7/7 - 0s - loss: 0.1699 - val_loss: 0.2020\n",
            "Epoch 88/200\n",
            "7/7 - 0s - loss: 0.1641 - val_loss: 0.2101\n",
            "Epoch 89/200\n",
            "7/7 - 0s - loss: 0.1624 - val_loss: 0.2110\n",
            "Epoch 90/200\n",
            "7/7 - 0s - loss: 0.1618 - val_loss: 0.2048\n",
            "Epoch 91/200\n",
            "7/7 - 0s - loss: 0.1758 - val_loss: 0.2097\n",
            "Epoch 92/200\n",
            "7/7 - 0s - loss: 0.1904 - val_loss: 0.2142\n",
            "Epoch 93/200\n",
            "7/7 - 0s - loss: 0.1734 - val_loss: 0.2099\n",
            "Epoch 94/200\n",
            "7/7 - 0s - loss: 0.1686 - val_loss: 0.1979\n",
            "Epoch 95/200\n",
            "7/7 - 0s - loss: 0.1687 - val_loss: 0.2061\n",
            "Epoch 96/200\n",
            "7/7 - 0s - loss: 0.1707 - val_loss: 0.2055\n",
            "Epoch 97/200\n",
            "7/7 - 0s - loss: 0.1615 - val_loss: 0.2015\n",
            "Epoch 98/200\n",
            "7/7 - 0s - loss: 0.1677 - val_loss: 0.2033\n",
            "Epoch 99/200\n",
            "7/7 - 0s - loss: 0.1666 - val_loss: 0.2134\n",
            "Epoch 100/200\n",
            "7/7 - 0s - loss: 0.1679 - val_loss: 0.1980\n",
            "Epoch 101/200\n",
            "7/7 - 0s - loss: 0.1577 - val_loss: 0.1985\n",
            "Epoch 102/200\n",
            "7/7 - 0s - loss: 0.1549 - val_loss: 0.1949\n",
            "Epoch 103/200\n",
            "7/7 - 0s - loss: 0.1675 - val_loss: 0.1914\n",
            "Epoch 104/200\n",
            "7/7 - 0s - loss: 0.1660 - val_loss: 0.1994\n",
            "Epoch 105/200\n",
            "7/7 - 0s - loss: 0.1613 - val_loss: 0.1892\n",
            "Epoch 106/200\n",
            "7/7 - 0s - loss: 0.1692 - val_loss: 0.1930\n",
            "Epoch 107/200\n",
            "7/7 - 0s - loss: 0.1630 - val_loss: 0.1924\n",
            "Epoch 108/200\n",
            "7/7 - 0s - loss: 0.1617 - val_loss: 0.1909\n",
            "Epoch 109/200\n",
            "7/7 - 0s - loss: 0.1507 - val_loss: 0.1927\n",
            "Epoch 110/200\n",
            "7/7 - 0s - loss: 0.1707 - val_loss: 0.1837\n",
            "Epoch 111/200\n",
            "7/7 - 0s - loss: 0.1638 - val_loss: 0.1957\n",
            "Epoch 112/200\n",
            "7/7 - 0s - loss: 0.1793 - val_loss: 0.1906\n",
            "Epoch 113/200\n",
            "7/7 - 0s - loss: 0.1955 - val_loss: 0.2097\n",
            "Epoch 114/200\n",
            "7/7 - 0s - loss: 0.1773 - val_loss: 0.1942\n",
            "Epoch 115/200\n",
            "7/7 - 0s - loss: 0.1689 - val_loss: 0.1869\n",
            "Epoch 116/200\n",
            "7/7 - 0s - loss: 0.1569 - val_loss: 0.1979\n",
            "Epoch 117/200\n",
            "7/7 - 0s - loss: 0.1627 - val_loss: 0.1903\n",
            "Epoch 118/200\n",
            "7/7 - 0s - loss: 0.1527 - val_loss: 0.1804\n",
            "Epoch 119/200\n",
            "7/7 - 0s - loss: 0.1637 - val_loss: 0.1867\n",
            "Epoch 120/200\n",
            "7/7 - 0s - loss: 0.1548 - val_loss: 0.1842\n",
            "Epoch 121/200\n",
            "7/7 - 0s - loss: 0.1577 - val_loss: 0.1867\n",
            "Epoch 122/200\n",
            "7/7 - 0s - loss: 0.1659 - val_loss: 0.1847\n",
            "Epoch 123/200\n",
            "7/7 - 0s - loss: 0.1606 - val_loss: 0.2104\n",
            "Epoch 124/200\n",
            "7/7 - 0s - loss: 0.1631 - val_loss: 0.1930\n",
            "Epoch 125/200\n",
            "7/7 - 0s - loss: 0.1586 - val_loss: 0.1777\n",
            "Epoch 126/200\n",
            "7/7 - 0s - loss: 0.1451 - val_loss: 0.1852\n",
            "Epoch 127/200\n",
            "7/7 - 0s - loss: 0.1398 - val_loss: 0.1911\n",
            "Epoch 128/200\n",
            "7/7 - 0s - loss: 0.1636 - val_loss: 0.1903\n",
            "Epoch 129/200\n",
            "7/7 - 0s - loss: 0.1428 - val_loss: 0.2011\n",
            "Epoch 130/200\n",
            "7/7 - 0s - loss: 0.1612 - val_loss: 0.1900\n",
            "Epoch 131/200\n",
            "7/7 - 0s - loss: 0.1558 - val_loss: 0.1910\n",
            "Epoch 132/200\n",
            "7/7 - 0s - loss: 0.1509 - val_loss: 0.1833\n",
            "Epoch 133/200\n",
            "7/7 - 0s - loss: 0.1497 - val_loss: 0.1972\n",
            "Epoch 134/200\n",
            "7/7 - 0s - loss: 0.1472 - val_loss: 0.1834\n",
            "Epoch 135/200\n",
            "7/7 - 0s - loss: 0.1464 - val_loss: 0.1821\n",
            "Epoch 136/200\n",
            "7/7 - 0s - loss: 0.1361 - val_loss: 0.1754\n",
            "Epoch 137/200\n",
            "7/7 - 0s - loss: 0.1565 - val_loss: 0.1848\n",
            "Epoch 138/200\n",
            "7/7 - 0s - loss: 0.1539 - val_loss: 0.1945\n",
            "Epoch 139/200\n",
            "7/7 - 0s - loss: 0.1633 - val_loss: 0.1941\n",
            "Epoch 140/200\n",
            "7/7 - 0s - loss: 0.1403 - val_loss: 0.1807\n",
            "Epoch 141/200\n",
            "7/7 - 0s - loss: 0.1511 - val_loss: 0.1678\n",
            "Epoch 142/200\n",
            "7/7 - 0s - loss: 0.1588 - val_loss: 0.1848\n",
            "Epoch 143/200\n",
            "7/7 - 0s - loss: 0.1666 - val_loss: 0.1814\n",
            "Epoch 144/200\n",
            "7/7 - 0s - loss: 0.1623 - val_loss: 0.1656\n",
            "Epoch 145/200\n",
            "7/7 - 0s - loss: 0.1601 - val_loss: 0.1899\n",
            "Epoch 146/200\n",
            "7/7 - 0s - loss: 0.1657 - val_loss: 0.1814\n",
            "Epoch 147/200\n",
            "7/7 - 0s - loss: 0.1575 - val_loss: 0.1805\n",
            "Epoch 148/200\n",
            "7/7 - 0s - loss: 0.1408 - val_loss: 0.1618\n",
            "Epoch 149/200\n",
            "7/7 - 0s - loss: 0.1483 - val_loss: 0.1663\n",
            "Epoch 150/200\n",
            "7/7 - 0s - loss: 0.1410 - val_loss: 0.1734\n",
            "Epoch 151/200\n",
            "7/7 - 0s - loss: 0.1460 - val_loss: 0.1900\n",
            "Epoch 152/200\n",
            "7/7 - 0s - loss: 0.1458 - val_loss: 0.1744\n",
            "Epoch 153/200\n",
            "7/7 - 0s - loss: 0.1477 - val_loss: 0.1615\n",
            "Epoch 154/200\n",
            "7/7 - 0s - loss: 0.1401 - val_loss: 0.1663\n",
            "Epoch 155/200\n",
            "7/7 - 0s - loss: 0.1453 - val_loss: 0.1725\n",
            "Epoch 156/200\n",
            "7/7 - 0s - loss: 0.1587 - val_loss: 0.1603\n",
            "Epoch 157/200\n",
            "7/7 - 0s - loss: 0.1539 - val_loss: 0.1654\n",
            "Epoch 158/200\n",
            "7/7 - 0s - loss: 0.1524 - val_loss: 0.1674\n",
            "Epoch 159/200\n",
            "7/7 - 0s - loss: 0.1379 - val_loss: 0.1708\n",
            "Epoch 160/200\n",
            "7/7 - 0s - loss: 0.1327 - val_loss: 0.1625\n",
            "Epoch 161/200\n",
            "7/7 - 0s - loss: 0.1405 - val_loss: 0.1565\n",
            "Epoch 162/200\n",
            "7/7 - 0s - loss: 0.1322 - val_loss: 0.1635\n",
            "Epoch 163/200\n",
            "7/7 - 0s - loss: 0.1347 - val_loss: 0.1625\n",
            "Epoch 164/200\n",
            "7/7 - 0s - loss: 0.1444 - val_loss: 0.1657\n",
            "Epoch 165/200\n",
            "7/7 - 0s - loss: 0.1423 - val_loss: 0.1636\n",
            "Epoch 166/200\n",
            "7/7 - 0s - loss: 0.1416 - val_loss: 0.1681\n",
            "Epoch 167/200\n",
            "7/7 - 0s - loss: 0.1455 - val_loss: 0.1636\n",
            "Epoch 168/200\n",
            "7/7 - 0s - loss: 0.1344 - val_loss: 0.1605\n",
            "Epoch 169/200\n",
            "7/7 - 0s - loss: 0.1393 - val_loss: 0.1710\n",
            "Epoch 170/200\n",
            "7/7 - 0s - loss: 0.1535 - val_loss: 0.1776\n",
            "Epoch 171/200\n",
            "7/7 - 0s - loss: 0.1553 - val_loss: 0.1654\n",
            "Epoch 172/200\n",
            "7/7 - 0s - loss: 0.1365 - val_loss: 0.1585\n",
            "Epoch 173/200\n",
            "7/7 - 0s - loss: 0.1321 - val_loss: 0.1568\n",
            "Epoch 174/200\n",
            "7/7 - 0s - loss: 0.1345 - val_loss: 0.1646\n",
            "Epoch 175/200\n",
            "7/7 - 0s - loss: 0.1338 - val_loss: 0.1787\n",
            "Epoch 176/200\n",
            "7/7 - 0s - loss: 0.1422 - val_loss: 0.1590\n",
            "Epoch 177/200\n",
            "7/7 - 0s - loss: 0.1422 - val_loss: 0.1613\n",
            "Epoch 178/200\n",
            "7/7 - 0s - loss: 0.1467 - val_loss: 0.1559\n",
            "Epoch 179/200\n",
            "7/7 - 0s - loss: 0.1379 - val_loss: 0.1572\n",
            "Epoch 180/200\n",
            "7/7 - 0s - loss: 0.1342 - val_loss: 0.1578\n",
            "Epoch 181/200\n",
            "7/7 - 0s - loss: 0.1414 - val_loss: 0.1575\n",
            "Epoch 182/200\n",
            "7/7 - 0s - loss: 0.1378 - val_loss: 0.1567\n",
            "Epoch 183/200\n",
            "7/7 - 0s - loss: 0.1349 - val_loss: 0.1638\n",
            "Epoch 184/200\n",
            "7/7 - 0s - loss: 0.1293 - val_loss: 0.1553\n",
            "Epoch 185/200\n",
            "7/7 - 0s - loss: 0.1366 - val_loss: 0.1585\n",
            "Epoch 186/200\n",
            "7/7 - 0s - loss: 0.1354 - val_loss: 0.1518\n",
            "Epoch 187/200\n",
            "7/7 - 0s - loss: 0.1343 - val_loss: 0.1493\n",
            "Epoch 188/200\n",
            "7/7 - 0s - loss: 0.1247 - val_loss: 0.1498\n",
            "Epoch 189/200\n",
            "7/7 - 0s - loss: 0.1211 - val_loss: 0.1462\n",
            "Epoch 190/200\n",
            "7/7 - 0s - loss: 0.1338 - val_loss: 0.1430\n",
            "Epoch 191/200\n",
            "7/7 - 0s - loss: 0.1264 - val_loss: 0.1430\n",
            "Epoch 192/200\n",
            "7/7 - 0s - loss: 0.1270 - val_loss: 0.1427\n",
            "Epoch 193/200\n",
            "7/7 - 0s - loss: 0.1334 - val_loss: 0.1503\n",
            "Epoch 194/200\n",
            "7/7 - 0s - loss: 0.1335 - val_loss: 0.1508\n",
            "Epoch 195/200\n",
            "7/7 - 0s - loss: 0.1213 - val_loss: 0.1399\n",
            "Epoch 196/200\n",
            "7/7 - 0s - loss: 0.1434 - val_loss: 0.1430\n",
            "Epoch 197/200\n",
            "7/7 - 0s - loss: 0.1405 - val_loss: 0.1445\n",
            "Epoch 198/200\n",
            "7/7 - 0s - loss: 0.1377 - val_loss: 0.1517\n",
            "Epoch 199/200\n",
            "7/7 - 0s - loss: 0.1401 - val_loss: 0.1440\n",
            "Epoch 200/200\n",
            "7/7 - 0s - loss: 0.1273 - val_loss: 0.1412\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f57b0191c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8QGmFvI14Zt",
        "colab_type": "text"
      },
      "source": [
        "#### 2-2-3. Model Evaluation\n",
        "The trained model is then evaluated based on the validation dataset that was separated out of the training dataset in data preprocessing. The model is evaluated by measuring its accuracy.\n",
        "\n",
        "*Please note that this step does not evaluate the model based on the test dataset and that it measures the accuracy based on the pairwise matching of the images - that is, if the given two images belong to the same class or not - not based on whether or not the model correctly predicts individual classes.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz25ecwc14Zu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict([x_test[:, 0], x_test[:, 1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufs-H8br14Zw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_accuracy(predictions, labels):\n",
        "  return labels[predictions.ravel() < 0.5].mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tsLgrSj914Zy",
        "colab_type": "code",
        "outputId": "8bc7a035-bc45-4e2f-84d8-eb255936b3a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "compute_accuracy(pred, y_test)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7333333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "el_7jwjTamoU",
        "colab_type": "text"
      },
      "source": [
        "The following code saves the weights of the trained model so that the model can be easily reused without having to train the model again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oMA3i1FJRBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save model\n",
        "# Purposely commented out the below code to prevent the currently using weights from getting overwritten\n",
        "model.save_weights(\"/content/drive/My Drive/U C Berkeley - Darragh/csv/siamese_custom_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7nr6cCEY7Kh",
        "colab_type": "text"
      },
      "source": [
        "The same model evaluation is performed using the weights loaded in the Google Drive in the above step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XC6KLOvMfZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trained_model = Model(inputs=[img_a, img_b], outputs=distance)\n",
        "trained_model.compile(loss=contrastive_loss, optimizer=optimizer)\n",
        "trained_model.load_weights(\"/content/drive/My Drive/U C Berkeley - Darragh/csv/siamese_custom_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zhbZ3JiMZh6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_values = trained_model.predict([x_test[:, 0], x_test[:, 1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-wpBOv_YwvU",
        "colab_type": "code",
        "outputId": "79b8738d-d48b-4fc2-806d-c2726c493920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "compute_accuracy(predicted_values, y_test)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7333333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnR66W-VHsJM",
        "colab_type": "text"
      },
      "source": [
        "## 3. Pretrained Model\n",
        "The same series of steps in Section 2 are taken below. The only difference between the previous section and this section is that the previous section uses a custom model, whereas this section uses a pretrained model - in this case, VGG16.\n",
        "\n",
        "Explanation of the below codes are omitted for the reason stated above except when there is any difference that needs to be noted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_EvJlDRVya2",
        "colab_type": "text"
      },
      "source": [
        "### 3-1. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYDY9Jv8V5dN",
        "colab_type": "text"
      },
      "source": [
        "#### 3-1-1. Data Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSrnNnKwVo33",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "76352011-44f2-4975-d875-6b2203a54338"
      },
      "source": [
        "# Initial model configuration setting based on the value given in the variable \"BASE_MODEL\"\n",
        "BASE_MODEL=\"vgg16\"  #Choices are: vgg16, mobilenetv2, xception\n",
        "\n",
        "if BASE_MODEL=='vgg16':\n",
        "  train_imagefile=\"Training-Images-224.csv\"\n",
        "  train_labelfile=\"Training-Labels-224.txt\"\n",
        "  test_imagefile=\"Test-Images-224.csv\"\n",
        "  test_labelfile=\"Test-Labels-224.txt\"\n",
        "  input_shape=(56,56,3) #(224,224,3)\n",
        "  pretrained_model='species_classification_vgg16_model.h5'\n",
        "  preprocessor=VGG16Pre\n",
        "  savefile='vgg16_best_model'\n",
        "  savemodel='vgg16_best_model.h5'\n",
        "  zero_model=VGG16(weights='imagenet',include_top=False,input_shape=input_shape,)\n",
        "elif BASE_MODEL==\"mobilenetv2\":\n",
        "  train_imagefile=\"Train-Images-Mobile-224.csv\"\n",
        "  train_labelfile=\"Train-Labels-Mobile-224.txt\"\n",
        "  test_imagefile=\"Test-Images-Mobile-224.csv\"\n",
        "  test_labelfile=\"Test-Labels-Mobile-224.txt\"\n",
        "  input_shape=(224,224,3)\n",
        "  pretrained_model='species_classification_mobilenetv2_model.h5'\n",
        "  preprocessor=MNPre\n",
        "  savefile='mobilenetv2_best_model'\n",
        "  zero_model=MobileNetV2(weights='imagenet',include_top=False,input_shape=input_shape)\n",
        "elif BASE_MODEL==\"xception\":\n",
        "  train_imagefile=\"Training-Images-Xception-224.csv\"\n",
        "  train_labelfile=\"Training-Labels-Xception-224.txt\"\n",
        "  test_imagefile=\"Test-Images-Xception-224.csv\"\n",
        "  test_labelfile=\"Test-Labels-Xception-224.txt\"\n",
        "  input_shape=(224,224,3)\n",
        "  pretrained_model='species_classification_xception_model.h5'\n",
        "  preprocessor=XceptionPre\n",
        "  savefile='xception_best_model'\n",
        "  zero_model=Xception(weights='imagenet',include_top=False,input_shape=input_shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oy0vIpf7csxL",
        "colab_type": "text"
      },
      "source": [
        "The only difference in the following `loadimgs2` function is that the below function does not change the images to grayscale and resizes the images to a different size, compared to `loadimgs` function in Section 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IclJfozEvWaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadimgs2(path):\n",
        "    total_individuals = 1\n",
        "    species_list = []\n",
        "    data_dict = {}\n",
        "\n",
        "    for species in os.listdir(path):\n",
        "        species_list.append(species)\n",
        "        print(\"loading species: \" + species)\n",
        "        species_path = os.path.join(path,species)\n",
        "        for individual in os.listdir(species_path):\n",
        "            individual_path = os.path.join(species_path, individual)\n",
        "            for filename in os.listdir(individual_path):\n",
        "                image_path = os.path.join(individual_path, filename)\n",
        "                image = cv2.imread(image_path)\n",
        "                if image is not None:\n",
        "                  #gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "                  resized_image=cv2.resize(image,(112,112),interpolation = cv2.INTER_AREA) #92,112\n",
        "                  array_1d = np.asarray(resized_image)\n",
        "                  if species+'-'+individual not in data_dict:\n",
        "                    data_dict[species+'-'+individual] = []\n",
        "                  data_dict[species+'-'+individual].append(array_1d)\n",
        "                  total_individuals += 1\n",
        "    return total_individuals, data_dict, species_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80BVGU_uvpqz",
        "colab_type": "code",
        "outputId": "844837c4-c51b-4b0c-9777-64305be0fe50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "print(\"---Loading Training Data...---\")\n",
        "train_size, train_data, train_species = loadimgs2(train_path)\n",
        "print(\"---Loading Test Data...---\")\n",
        "test_size, test_data, test_species = loadimgs2(test_path)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---Loading Training Data...---\n",
            "loading species: Amur Tiger\n",
            "loading species: Bengal Tiger\n",
            "loading species: Cheetah\n",
            "loading species: Leopard\n",
            "loading species: Lowland Tapir\n",
            "loading species: Puma\n",
            "loading species: White Rhino\n",
            "loading species: Black Rhino\n",
            "loading species: African lion\n",
            "loading species: African elephant\n",
            "loading species: Bongo\n",
            "---Loading Test Data...---\n",
            "loading species: Amur Tiger\n",
            "loading species: Bengal Tiger\n",
            "loading species: Cheetah\n",
            "loading species: Leopard\n",
            "loading species: Lowland Tapir\n",
            "loading species: Puma\n",
            "loading species: White Rhino\n",
            "loading species: Black Rhino\n",
            "loading species: African lion\n",
            "loading species: African elephant\n",
            "loading species: Bongo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xVZWFJWv4Z6",
        "colab_type": "code",
        "outputId": "2d833694-3ebe-412c-d495-de4ac7d8c7ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data[\"Amur Tiger-261\"][0].shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(112, 112, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyGdMpGmxgEA",
        "colab_type": "code",
        "outputId": "9ff56b42-390f-4e57-fc2a-6b202c67d183",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data[\"Amur Tiger-261\"][0][::size, ::size, ::].shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56, 56, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbO3N-7RdXdu",
        "colab_type": "text"
      },
      "source": [
        "#### 3-1-2. Generating Training Dataset\n",
        "The only difference in the following function from the the corresponding function in Section 2 is that `get_data2` function creates the final numpy arrays with different shapes because images are not converted to grayscale in this step - images shapes take a form of (X, X, 3) instead of (X, X)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awotq4HGxDck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data2(size, total_sample_size, dataset):\n",
        "  image = dataset[\"Amur Tiger-261\"][0]\n",
        "  image = image[::size, ::size, ::]\n",
        "  dim1 = image.shape[0]\n",
        "  dim2 = image.shape[1]\n",
        "    \n",
        "  # Initialize the numpy array with the shape of [total_sample, no_of_pairs, dim1, dim2]\n",
        "  x_genuine_pair = np.zeros([total_sample_size, 2, dim1, dim2, 3])  # 2 is for pairs\n",
        "  y_genuine = np.zeros([total_sample_size, 1])\n",
        "\n",
        "  x_imposite_pair = np.zeros([total_sample_size, 2, dim1, dim2, 3])\n",
        "  y_imposite = np.zeros([total_sample_size, 1])\n",
        "\n",
        "  species_dict = {}\n",
        "  individuals = list(dataset.keys())\n",
        "\n",
        "  # Generates all possible pairs of the two images within the same species\n",
        "  for species in train_species:\n",
        "\n",
        "    # Filter only individuals within the same species\n",
        "    individuals_new = [ind for ind in individuals if ind.find(species) != -1]\n",
        "\n",
        "    # Same individual pairs\n",
        "    count1 = 0\n",
        "    print(\"Generating same individual pairs for \"+species)\n",
        "    for ind in individuals_new:\n",
        "      footprints = dataset[ind]\n",
        "      max_idx = len(footprints) - 1\n",
        "      for idx, img in enumerate(footprints):\n",
        "        counter = idx + 1\n",
        "        while counter <= max_idx:\n",
        "          img1 = img\n",
        "          img2 = footprints[counter]\n",
        "          # Reduce the size\n",
        "          img1 = img1[::size, ::size, ::]\n",
        "          img2 = img2[::size, ::size, ::]\n",
        "          # Store the images to the initialized numpy array\n",
        "          x_genuine_pair[count1, 0, :, :, :] = img1\n",
        "          x_genuine_pair[count1, 1, :, :, :] = img2\n",
        "          # Assign the label as one as we are drawing images from the same individual (genuine pair)\n",
        "          y_genuine[count1] = 1\n",
        "          counter += 1\n",
        "          count1 += 1\n",
        "\n",
        "    # Different individual pairs\n",
        "    count2 = 0\n",
        "    print(\"Generating different individual pairs for \"+species)\n",
        "    for idx, img in enumerate(individuals_new[:-1]):\n",
        "      ind1 = individuals_new[idx]\n",
        "      footprints1 = dataset[ind1]\n",
        "      ind2_list = individuals_new[idx+1:]\n",
        "      for idx2, img2 in enumerate(ind2_list):\n",
        "        ind2 = ind2_list[idx2]\n",
        "        footprints2 = dataset[ind2]\n",
        "        #print(ind1, ind2)\n",
        "        for fp1 in footprints1:\n",
        "          for fp2 in footprints2:\n",
        "            img1 = fp1\n",
        "            img2 = fp2\n",
        "            # Reduce the size\n",
        "            img1 = img1[::size, ::size, ::]\n",
        "            img2 = img2[::size, ::size, ::]\n",
        "            # Store the images to the initialized numpy array\n",
        "            x_imposite_pair[count2, 0, :, :, :] = img1\n",
        "            x_imposite_pair[count2, 1, :, :, :] = img2\n",
        "            # Assign the label as zero as we are drawing images from different individuals\n",
        "            y_imposite[count2] = 0\n",
        "            count2 += 1\n",
        "  \n",
        "  # Generate the same number of pairs for two target classes (0: different individuals, 1: same individuals)\n",
        "  count = min(count1, count2)\n",
        "\n",
        "  x_genuine_pair_new = np.zeros([count, 2, dim1, dim2, 3])  # 2 is for pairs\n",
        "  y_genuine_new = np.zeros([count, 1])\n",
        "\n",
        "  x_imposite_pair_new = np.zeros([count, 2, dim1, dim2, 3])\n",
        "  y_imposite_new = np.zeros([count, 1])\n",
        "\n",
        "  genuine_idx = np.random.choice(range(count1), count, replace=False)\n",
        "  imposite_idx = np.random.choice(range(count2), count, replace=False)\n",
        "\n",
        "  for idx1, idx2, counter in zip(genuine_idx, imposite_idx, range(count)):\n",
        "    x_genuine_pair_new[counter, 0, :, :, :] = x_genuine_pair[idx1, 0, :, :, :]\n",
        "    x_genuine_pair_new[counter, 1, :, :, :] = x_genuine_pair[idx1, 1, :, :, :]\n",
        "    y_genuine_new[counter] = 1\n",
        "\n",
        "    x_imposite_pair_new[counter, 0, :, :, :] = x_imposite_pair[idx2, 0, :, :, :]\n",
        "    x_imposite_pair_new[counter, 1, :, :, :] = x_imposite_pair[idx2, 1, :, :, :]\n",
        "    y_imposite_new[counter] = 0\n",
        "\n",
        "  # Concatenate genuine pairs and imposite pairs to get the whole data\n",
        "  X = np.concatenate([x_genuine_pair_new, x_imposite_pair_new], axis=0)/255\n",
        "  Y = np.concatenate([y_genuine_new, y_imposite_new], axis=0)\n",
        "  print(\"The End\")\n",
        "  return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr9gxhZCyMJW",
        "colab_type": "code",
        "outputId": "59a8983f-75fb-4d2c-aabb-6a2bf26ba823",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "size = 2\n",
        "total_sample_size = 50000\n",
        "X, Y = get_data2(size, total_sample_size, train_data)\n",
        "print(len(X), len(Y))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating same individual pairs for Amur Tiger\n",
            "Generating different individual pairs for Amur Tiger\n",
            "Generating same individual pairs for Bengal Tiger\n",
            "Generating different individual pairs for Bengal Tiger\n",
            "Generating same individual pairs for Cheetah\n",
            "Generating different individual pairs for Cheetah\n",
            "Generating same individual pairs for Leopard\n",
            "Generating different individual pairs for Leopard\n",
            "Generating same individual pairs for Lowland Tapir\n",
            "Generating different individual pairs for Lowland Tapir\n",
            "Generating same individual pairs for Puma\n",
            "Generating different individual pairs for Puma\n",
            "Generating same individual pairs for White Rhino\n",
            "Generating different individual pairs for White Rhino\n",
            "Generating same individual pairs for Black Rhino\n",
            "Generating different individual pairs for Black Rhino\n",
            "Generating same individual pairs for African lion\n",
            "Generating different individual pairs for African lion\n",
            "Generating same individual pairs for African elephant\n",
            "Generating different individual pairs for African elephant\n",
            "Generating same individual pairs for Bongo\n",
            "Generating different individual pairs for Bongo\n",
            "The End\n",
            "796 796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5i_7PDFd8S8",
        "colab_type": "text"
      },
      "source": [
        "#### 3-1-3. Data Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVdCHC4eynTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPXkBU75y1NR",
        "colab_type": "code",
        "outputId": "63597261-ea51-430f-af0d-fa65f1713822",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(597, 2, 56, 56, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF1-d2dXePYj",
        "colab_type": "text"
      },
      "source": [
        "### 3-2. Model Development"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBSqWelneZxU",
        "colab_type": "text"
      },
      "source": [
        "#### 3-2-1. Base Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWPciIML2v-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_1 = x_train[:, 0]\n",
        "img_2 = x_train[:, 1]\n",
        "\n",
        "csvpath='/content/drive/My Drive/U C Berkeley - Darragh/csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcJ_2HVqtHnP",
        "colab_type": "code",
        "outputId": "6e97e4e3-b759-409b-f0f5-456439cbed5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "img_1.shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(597, 56, 56, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfV9Hcvk6u86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape = (56, 56, 3)\n",
        "left_input=Input(input_shape)\n",
        "right_input=Input(input_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nWf6sKO88nX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createSiameseNetwork(input_shape):\n",
        "  model = Sequential()\n",
        "  model.add(zero_model)\n",
        "\n",
        "  # Flatten\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(50, activation='relu'))\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkCsVz3L6Up5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_network = createSiameseNetwork((56, 56, 3))\n",
        "feat_vecs_a = base_network(left_input)\n",
        "feat_vecs_b = base_network(right_input)\n",
        "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([feat_vecs_a, feat_vecs_b])\n",
        "    \n",
        "# Connect the inputs with the outputs\n",
        "siamese = Model(inputs=[left_input,right_input],outputs=distance)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C3Sg3PkL2jt",
        "colab_type": "code",
        "outputId": "096af6ff-99bb-4c15-abda-676207e0802d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "siamese.summary()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 56, 56, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, 56, 56, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, 50)           14786802    input_4[0][0]                    \n",
            "                                                                 input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 1)            0           sequential_1[1][0]               \n",
            "                                                                 sequential_1[2][0]               \n",
            "==================================================================================================\n",
            "Total params: 14,786,802\n",
            "Trainable params: 14,786,802\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qvyEN8ze7uD",
        "colab_type": "text"
      },
      "source": [
        "#### 3-2-2. Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8q0kjs-HrnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4IzSYW_q1dU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "siamese.compile(loss=contrastive_loss, optimizer=Adam(lr = 0.0005))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-7BPfMMq-vC",
        "colab_type": "code",
        "outputId": "2e93100c-8ee1-48bb-f77a-e4e684ac338f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "siamese.fit([img_1, img_2], y_train, validation_split=.25, batch_size=64, verbose=2, epochs=epochs)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "7/7 - 2s - loss: 21.1536 - val_loss: 0.4452\n",
            "Epoch 2/50\n",
            "7/7 - 1s - loss: 0.2972 - val_loss: 0.4060\n",
            "Epoch 3/50\n",
            "7/7 - 1s - loss: 0.2729 - val_loss: 0.3515\n",
            "Epoch 4/50\n",
            "7/7 - 1s - loss: 0.2518 - val_loss: 0.2721\n",
            "Epoch 5/50\n",
            "7/7 - 1s - loss: 0.2299 - val_loss: 0.2674\n",
            "Epoch 6/50\n",
            "7/7 - 1s - loss: 0.2249 - val_loss: 0.2622\n",
            "Epoch 7/50\n",
            "7/7 - 1s - loss: 0.2312 - val_loss: 0.2067\n",
            "Epoch 8/50\n",
            "7/7 - 1s - loss: 0.2063 - val_loss: 0.2015\n",
            "Epoch 9/50\n",
            "7/7 - 1s - loss: 0.1951 - val_loss: 0.1948\n",
            "Epoch 10/50\n",
            "7/7 - 1s - loss: 0.1853 - val_loss: 0.1873\n",
            "Epoch 11/50\n",
            "7/7 - 1s - loss: 0.1676 - val_loss: 0.1759\n",
            "Epoch 12/50\n",
            "7/7 - 1s - loss: 0.1450 - val_loss: 0.1620\n",
            "Epoch 13/50\n",
            "7/7 - 1s - loss: 0.1553 - val_loss: 0.1499\n",
            "Epoch 14/50\n",
            "7/7 - 1s - loss: 0.1828 - val_loss: 0.1650\n",
            "Epoch 15/50\n",
            "7/7 - 1s - loss: 0.1521 - val_loss: 0.1722\n",
            "Epoch 16/50\n",
            "7/7 - 1s - loss: 0.1424 - val_loss: 0.1765\n",
            "Epoch 17/50\n",
            "7/7 - 1s - loss: 0.1540 - val_loss: 0.1330\n",
            "Epoch 18/50\n",
            "7/7 - 1s - loss: 0.1317 - val_loss: 0.1234\n",
            "Epoch 19/50\n",
            "7/7 - 1s - loss: 0.1228 - val_loss: 0.1227\n",
            "Epoch 20/50\n",
            "7/7 - 1s - loss: 0.1462 - val_loss: 0.1583\n",
            "Epoch 21/50\n",
            "7/7 - 1s - loss: 0.1264 - val_loss: 0.1317\n",
            "Epoch 22/50\n",
            "7/7 - 1s - loss: 0.1142 - val_loss: 0.1126\n",
            "Epoch 23/50\n",
            "7/7 - 1s - loss: 0.1057 - val_loss: 0.1302\n",
            "Epoch 24/50\n",
            "7/7 - 1s - loss: 0.0985 - val_loss: 0.1262\n",
            "Epoch 25/50\n",
            "7/7 - 1s - loss: 0.0941 - val_loss: 0.0877\n",
            "Epoch 26/50\n",
            "7/7 - 1s - loss: 0.0911 - val_loss: 0.1078\n",
            "Epoch 27/50\n",
            "7/7 - 1s - loss: 0.0872 - val_loss: 0.0920\n",
            "Epoch 28/50\n",
            "7/7 - 1s - loss: 0.0885 - val_loss: 0.1037\n",
            "Epoch 29/50\n",
            "7/7 - 1s - loss: 0.1074 - val_loss: 0.1089\n",
            "Epoch 30/50\n",
            "7/7 - 1s - loss: 0.0900 - val_loss: 0.0822\n",
            "Epoch 31/50\n",
            "7/7 - 1s - loss: 0.0730 - val_loss: 0.1121\n",
            "Epoch 32/50\n",
            "7/7 - 1s - loss: 0.0748 - val_loss: 0.0720\n",
            "Epoch 33/50\n",
            "7/7 - 1s - loss: 0.0615 - val_loss: 0.0626\n",
            "Epoch 34/50\n",
            "7/7 - 1s - loss: 0.0493 - val_loss: 0.0693\n",
            "Epoch 35/50\n",
            "7/7 - 1s - loss: 0.0564 - val_loss: 0.0767\n",
            "Epoch 36/50\n",
            "7/7 - 1s - loss: 0.0587 - val_loss: 0.0756\n",
            "Epoch 37/50\n",
            "7/7 - 1s - loss: 0.0694 - val_loss: 0.1321\n",
            "Epoch 38/50\n",
            "7/7 - 1s - loss: 0.0887 - val_loss: 0.0754\n",
            "Epoch 39/50\n",
            "7/7 - 1s - loss: 0.0656 - val_loss: 0.0635\n",
            "Epoch 40/50\n",
            "7/7 - 1s - loss: 0.0606 - val_loss: 0.0841\n",
            "Epoch 41/50\n",
            "7/7 - 1s - loss: 0.0643 - val_loss: 0.0657\n",
            "Epoch 42/50\n",
            "7/7 - 1s - loss: 0.0474 - val_loss: 0.0500\n",
            "Epoch 43/50\n",
            "7/7 - 1s - loss: 0.0482 - val_loss: 0.0623\n",
            "Epoch 44/50\n",
            "7/7 - 1s - loss: 0.0468 - val_loss: 0.0775\n",
            "Epoch 45/50\n",
            "7/7 - 1s - loss: 0.0528 - val_loss: 0.0605\n",
            "Epoch 46/50\n",
            "7/7 - 1s - loss: 0.0497 - val_loss: 0.0678\n",
            "Epoch 47/50\n",
            "7/7 - 1s - loss: 0.0447 - val_loss: 0.0544\n",
            "Epoch 48/50\n",
            "7/7 - 1s - loss: 0.0443 - val_loss: 0.0674\n",
            "Epoch 49/50\n",
            "7/7 - 1s - loss: 0.0406 - val_loss: 0.0488\n",
            "Epoch 50/50\n",
            "7/7 - 1s - loss: 0.0430 - val_loss: 0.0685\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f57962431d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9lJrQKSfE8f",
        "colab_type": "text"
      },
      "source": [
        "#### 3-2-3. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6To3h_9a0x5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = siamese.predict([x_test[:, 0], x_test[:, 1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nuy155n7RLKM",
        "colab_type": "code",
        "outputId": "69cf3e27-5f02-47b9-ed90-58266025764e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "compute_accuracy(pred, y_test)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.912621359223301"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "696nqIJ0CHNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "siamese.save_weights(\"/content/drive/My Drive/U C Berkeley - Darragh/csv/siamese_vgg16_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j4nu6msJq8Z",
        "colab_type": "text"
      },
      "source": [
        "## 4. Model Evaluation with True Test Dataset\n",
        "The following code evaluates the model based on test dataset instead of validation dataset. Also, instead of measuring the accuracy based on pairwise matching prediction, it measure the true accuracy - that is, how well the model predicts individuals."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzGghHOiEMpV",
        "colab_type": "code",
        "outputId": "aeb731c3-1c01-494f-a8e4-6866796a0e97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(test_species)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Amur Tiger', 'Bengal Tiger', 'Cheetah', 'Leopard', 'Lowland Tapir', 'Puma', 'White Rhino', 'Black Rhino', 'African lion', 'African elephant', 'Bongo']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya4kl73rESW1",
        "colab_type": "code",
        "outputId": "340c6940-a619-45a3-865d-389004cac68f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(test_data.keys())"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['Amur Tiger-237', 'Amur Tiger-261', 'Amur Tiger-279', 'Amur Tiger-440', 'Amur Tiger-565', 'Amur Tiger-682', 'Amur Tiger-1020', 'Bengal Tiger-Aria', 'Bengal Tiger-Fenimore', 'Bengal Tiger-India', 'Bengal Tiger-Lucky', 'Bengal Tiger-Moki', 'Bengal Tiger-Mona', 'Bengal Tiger-Rajah', 'Bengal Tiger-Rajaji', 'Cheetah-Alvin', 'Cheetah-Aiko', 'Cheetah-Chiquita', 'Cheetah-Tearmark', 'Cheetah-Jamu', 'Cheetah-Kiki', 'Cheetah-Rusty', 'Cheetah-Sandy', 'Cheetah-Pano', 'Leopard-Keanu', 'Leopard-Shakira', 'Leopard-Lewa', 'Leopard-Mick', 'Leopard-Tony', 'Leopard-Timbila', 'Leopard-Wahoo', 'Leopard-Ombeli', 'Lowland Tapir-Chuva F', 'Lowland Tapir-Chuvisco M', 'Lowland Tapir-Edinha F', 'Lowland Tapir-Feminha F', 'Lowland Tapir-Pistolinha M', 'Lowland Tapir-Riscado M', 'Lowland Tapir-Sorocaba', 'Lowland Tapir-Sorocaba 2', 'Lowland Tapir-Sorocaba 5', 'Puma-F-Archback', 'Puma-F-Cassie', 'Puma-F-Lip', 'Puma-F-Spots', 'Puma-M-Darby', 'Puma-M-Juvboy', 'Puma-M-Oldex', 'Puma-M-Phoenix', 'Puma-M-Pops', 'Puma-M-Skit', 'Puma-M-Taz', 'Puma-F-Tawny', 'Puma-F-Majanna', 'White Rhino-Kal Cs 6JunKML2', 'White Rhino-Kal Cs 9JunKML3', 'White Rhino-Kalakwa Cs5', 'White Rhino-Kalakwa Cs6', 'White Rhino-Kalakwa Cs7', 'White Rhino-Kalakwa Cs10', 'White Rhino-Kalakwa Cs15', 'White Rhino-Kalakwa Cs17', 'Black Rhino-Kal Db Himb', 'Black Rhino-Kal Db Jav', 'Black Rhino-Kal Db Kuz', 'Black Rhino-Kal Db M1', 'Black Rhino-Kal Db M2', 'Black Rhino-Kuz Db Col', 'Black Rhino-Kuz Db Hec', 'Black Rhino-Kuz Db Hel', 'Black Rhino-Kuz Db Ken', 'African lion-Mogli', 'African lion-Inca', 'African lion-Ceasar', 'African lion-Jan', 'African lion-Jamu', 'African lion-Maro', 'African lion-Elsa', 'African lion-Mapivu', 'African lion-Bijan', 'African lion-Elangeny', 'African elephant-Chikenya', 'African elephant-Paseka', 'African elephant-Thandi', 'African elephant-Lorato', 'African elephant-Sukeri', 'African elephant-Thato', 'African elephant-Mashudu', 'African elephant-Sene', 'African elephant-Abu', 'Bongo-Rehema', 'Bongo-Bambi', 'Bongo-Amani', 'Bongo-Lucy', 'Bongo-Nolano', 'Bongo-Nengese', 'Bongo-Malaika', 'Bongo-Kalama'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDa5ky-jJp-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load trained model - VGG16\n",
        "trained_model = Model(inputs=[left_input, right_input], outputs=distance)\n",
        "trained_model.compile(loss=contrastive_loss, optimizer='adam', metrics=['accuracy'])\n",
        "trained_model.load_weights(\"/content/drive/My Drive/U C Berkeley - Darragh/csv/siamese_vgg16_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLl_maibZ-Js",
        "colab_type": "code",
        "outputId": "9381f771-4b9d-4e6f-a7a9-d6b599a2778d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "species_dict = {}\n",
        "for species in test_species:\n",
        "  for individual in train_data.keys():\n",
        "    if species in individual:\n",
        "      if species not in species_dict:\n",
        "        species_dict[species] = [individual]\n",
        "      else:\n",
        "        species_dict[species].append(individual)\n",
        "        \n",
        "print(species_dict)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Amur Tiger': ['Amur Tiger-261', 'Amur Tiger-237', 'Amur Tiger-279', 'Amur Tiger-440', 'Amur Tiger-565', 'Amur Tiger-682', 'Amur Tiger-1020'], 'Bengal Tiger': ['Bengal Tiger-Aria', 'Bengal Tiger-Fenimore', 'Bengal Tiger-India', 'Bengal Tiger-Lucky', 'Bengal Tiger-Moki', 'Bengal Tiger-Mona', 'Bengal Tiger-Rajah', 'Bengal Tiger-Rajaji'], 'Cheetah': ['Cheetah-Aiko', 'Cheetah-Alvin', 'Cheetah-Chiquita', 'Cheetah-Jamu', 'Cheetah-Kiki', 'Cheetah-Pano', 'Cheetah-Rusty', 'Cheetah-Sandy', 'Cheetah-Tearmark'], 'Leopard': ['Leopard-Keanu', 'Leopard-Lewa', 'Leopard-Mick', 'Leopard-Ombeli', 'Leopard-Timbila', 'Leopard-Tony', 'Leopard-Wahoo', 'Leopard-Shakira'], 'Lowland Tapir': ['Lowland Tapir-Sorocaba 2', 'Lowland Tapir-Chuva F', 'Lowland Tapir-Sorocaba 5', 'Lowland Tapir-Edinha F', 'Lowland Tapir-Feminha F', 'Lowland Tapir-Pistolinha M', 'Lowland Tapir-Sorocaba', 'Lowland Tapir-Chuvisco M', 'Lowland Tapir-Riscado M'], 'Puma': ['Puma-M-Taz', 'Puma-M-Skit', 'Puma-M-Pops', 'Puma-M-Phoenix', 'Puma-M-Oldex', 'Puma-M-Juvboy', 'Puma-M-Darby', 'Puma-F-Tawny', 'Puma-F-Spots', 'Puma-F-Majanna', 'Puma-F-Lip', 'Puma-F-Cassie', 'Puma-F-Archback'], 'White Rhino': ['White Rhino-Kalakwa Cs10', 'White Rhino-Kalakwa Cs5', 'White Rhino-Kalakwa Cs15', 'White Rhino-Kalakwa Cs6', 'White Rhino-Kal Cs 9JunKML3', 'White Rhino-Kal Cs 6JunKML2', 'White Rhino-Kalakwa Cs7', 'White Rhino-Kalakwa Cs17'], 'Black Rhino': ['Black Rhino-Kal Db Himb', 'Black Rhino-Kal Db Jav', 'Black Rhino-Kal Db Kuz', 'Black Rhino-Kal Db M1', 'Black Rhino-Kal Db M2', 'Black Rhino-Kuz Db Col', 'Black Rhino-Kuz Db Hec', 'Black Rhino-Kuz Db Hel', 'Black Rhino-Kuz Db Ken'], 'African lion': ['African lion-Jamu', 'African lion-Mogli', 'African lion-Ceasar', 'African lion-Maro', 'African lion-Jan', 'African lion-Elsa', 'African lion-Inca', 'African lion-Elangeny', 'African lion-Mapivu', 'African lion-Bijan'], 'African elephant': ['African elephant-Mashudu', 'African elephant-Abu', 'African elephant-Thandi', 'African elephant-Chikenya', 'African elephant-Lorato', 'African elephant-Sukeri', 'African elephant-Sene', 'African elephant-Thato', 'African elephant-Paseka'], 'Bongo': ['Bongo-Rehema', 'Bongo-Lucy', 'Bongo-Kalama', 'Bongo-Nolano', 'Bongo-Bambi', 'Bongo-Malaika', 'Bongo-Nengese', 'Bongo-Amani']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kB4AHCxyfgY8",
        "colab_type": "text"
      },
      "source": [
        "The following code generates pairs of images - it pairs a base image (from test dataset) with one random image from every individual within the species of the base image. (This needs to modified in the future to extract one representative image from each individual instead of one random image.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHm_ASsDygmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "size = 2\n",
        "\n",
        "def generate_test_pairs(size, train_data, test_data):\n",
        "  image = train_data[\"Amur Tiger-261\"][0]\n",
        "  image = image[::size, ::size, ::]\n",
        "  dim1 = image.shape[0]\n",
        "  dim2 = image.shape[1]\n",
        "\n",
        "  pairs = []\n",
        "  idx1 = 0\n",
        "  idx2 = 0\n",
        "\n",
        "  x_pair = np.zeros([3000, 2, dim1, dim2, 3])  # 2 is for pairs\n",
        "\n",
        "  for ind in test_data.keys():\n",
        "    species = ind[:ind.find(\"-\")]\n",
        "    individuals = species_dict[species]\n",
        "    for footprint in test_data[ind]:\n",
        "      for item in individuals:\n",
        "        footprints = train_data[item]\n",
        "        total_samples = len(footprints)\n",
        "        sample = np.random.choice(range(total_samples), 1, replace=False) # Needs to replace this with representative image for each individual instead of random sampling\n",
        "        sample_image = footprints[sample[0]]\n",
        "        img1 = footprint\n",
        "        img2 = sample_image\n",
        "        # Reduce the size\n",
        "        img1 = img1[::size, ::size, ::]\n",
        "        img2 = img2[::size, ::size, ::]\n",
        "        # Store the images to the initialized numpy array\n",
        "        x_pair[idx1, 0, :, :, :] = img1\n",
        "        x_pair[idx1, 1, :, :, :] = img2\n",
        "        pairs.append((idx2, ind, item))\n",
        "        idx1 += 1\n",
        "      idx2 += 1\n",
        "\n",
        "  x_pair_new = np.zeros([idx1, 2, dim1, dim2, 3])  # 2 is for pairs\n",
        "  for counter in range(idx1):\n",
        "      x_pair_new[counter, 0, :, :, :] = x_pair[counter, 0, :, :, :]\n",
        "      x_pair_new[counter, 1, :, :, :] = x_pair[counter, 1, :, :, :]\n",
        "\n",
        "  # Concatenate genuine pairs and imposite pairs to get the whole data\n",
        "  X = np.concatenate([x_pair_new], axis=0)/255\n",
        "\n",
        "  return pairs, X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O9i0MqYqb-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_test_pairs, x_real_test = generate_test_pairs(size, train_data, test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpg6_87o-LW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_predicted_values = trained_model.predict([x_real_test[:, 0], x_real_test[:, 1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvT1gHcCBTIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = np.concatenate([real_test_pairs, real_predicted_values], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UYQzP9YgnIk",
        "colab_type": "text"
      },
      "source": [
        "Then, the output values of the model are compared for every test image to select the individual that has the lowest value. It is assumed that the value with the lowest value represents the class of individual that the test image most likely belongs to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mi7CdXp_P3b",
        "colab_type": "code",
        "outputId": "9206a904-e09b-4d3d-8875-0cd12c3b21a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "results_dict = {}\n",
        "\n",
        "for image, actual_ind, test_ind, score in results:\n",
        "  if image not in results_dict:\n",
        "    results_dict[image] = [actual_ind, test_ind, score]\n",
        "  existing_score = results_dict[image][2]\n",
        "  if score < existing_score:\n",
        "    results_dict[image] = [actual_ind, test_ind, score]\n",
        "\n",
        "print(results_dict)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'0': ['Amur Tiger-237', 'Amur Tiger-682', '0.29614305'], '1': ['Amur Tiger-261', 'Amur Tiger-682', '0.017769689'], '2': ['Amur Tiger-261', 'Amur Tiger-261', '0.05716519'], '3': ['Amur Tiger-279', 'Amur Tiger-1020', '0.028992444'], '4': ['Amur Tiger-440', 'Amur Tiger-682', '0.01969221'], '5': ['Amur Tiger-440', 'Amur Tiger-440', '0.19495362'], '6': ['Amur Tiger-565', 'Amur Tiger-565', '0.05082969'], '7': ['Amur Tiger-682', 'Amur Tiger-682', '0.61025023'], '8': ['Amur Tiger-682', 'Amur Tiger-565', '0.12156996'], '9': ['Amur Tiger-1020', 'Amur Tiger-565', '0.02764908'], '10': ['Amur Tiger-1020', 'Amur Tiger-279', '0.091716945'], '11': ['Bengal Tiger-Aria', 'Bengal Tiger-Mona', '0.18202755'], '12': ['Bengal Tiger-Aria', 'Bengal Tiger-India', '0.28897348'], '13': ['Bengal Tiger-Aria', 'Bengal Tiger-Moki', '0.22625233'], '14': ['Bengal Tiger-Fenimore', 'Bengal Tiger-Moki', '0.0055234483'], '15': ['Bengal Tiger-Fenimore', 'Bengal Tiger-Rajah', '0.16140138'], '16': ['Bengal Tiger-India', 'Bengal Tiger-Fenimore', '0.028632356'], '17': ['Bengal Tiger-India', 'Bengal Tiger-India', '0.7568235'], '18': ['Bengal Tiger-India', 'Bengal Tiger-India', '0.26023778'], '19': ['Bengal Tiger-Lucky', 'Bengal Tiger-Moki', '0.045291632'], '20': ['Bengal Tiger-Lucky', 'Bengal Tiger-Rajah', '0.040829737'], '21': ['Bengal Tiger-Moki', 'Bengal Tiger-Moki', '0.42438537'], '22': ['Bengal Tiger-Mona', 'Bengal Tiger-Lucky', '0.08859392'], '23': ['Bengal Tiger-Mona', 'Bengal Tiger-Rajah', '0.045884423'], '24': ['Bengal Tiger-Rajah', 'Bengal Tiger-India', '0.42449662'], '25': ['Bengal Tiger-Rajaji', 'Bengal Tiger-India', '0.09960604'], '26': ['Bengal Tiger-Rajaji', 'Bengal Tiger-Rajaji', '0.042678338'], '27': ['Cheetah-Alvin', 'Cheetah-Alvin', '0.058249988'], '28': ['Cheetah-Alvin', 'Cheetah-Aiko', '0.14095089'], '29': ['Cheetah-Alvin', 'Cheetah-Chiquita', '0.19114757'], '30': ['Cheetah-Aiko', 'Cheetah-Pano', '0.075823836'], '31': ['Cheetah-Aiko', 'Cheetah-Rusty', '0.07157349'], '32': ['Cheetah-Chiquita', 'Cheetah-Tearmark', '0.18251945'], '33': ['Cheetah-Chiquita', 'Cheetah-Pano', '0.051300265'], '34': ['Cheetah-Chiquita', 'Cheetah-Kiki', '0.26847842'], '35': ['Cheetah-Chiquita', 'Cheetah-Pano', '0.12390014'], '36': ['Cheetah-Tearmark', 'Cheetah-Aiko', '0.46718523'], '37': ['Cheetah-Tearmark', 'Cheetah-Aiko', '0.1577318'], '38': ['Cheetah-Jamu', 'Cheetah-Chiquita', '0.037666388'], '39': ['Cheetah-Jamu', 'Cheetah-Chiquita', '0.04748454'], '40': ['Cheetah-Kiki', 'Cheetah-Jamu', '0.03605575'], '41': ['Cheetah-Kiki', 'Cheetah-Kiki', '0.17100424'], '42': ['Cheetah-Rusty', 'Cheetah-Sandy', '0.23061416'], '43': ['Cheetah-Rusty', 'Cheetah-Pano', '0.062293485'], '44': ['Cheetah-Rusty', 'Cheetah-Alvin', '0.28827763'], '45': ['Cheetah-Sandy', 'Cheetah-Rusty', '0.13669938'], '46': ['Cheetah-Sandy', 'Cheetah-Kiki', '0.8651657'], '47': ['Cheetah-Sandy', 'Cheetah-Pano', '0.08829942'], '48': ['Cheetah-Pano', 'Cheetah-Aiko', '0.07154054'], '49': ['Cheetah-Pano', 'Cheetah-Rusty', '0.16150695'], '50': ['Cheetah-Pano', 'Cheetah-Chiquita', '0.18869583'], '51': ['Leopard-Keanu', 'Leopard-Tony', '0.09765132'], '52': ['Leopard-Keanu', 'Leopard-Tony', '0.34817007'], '53': ['Leopard-Shakira', 'Leopard-Wahoo', '0.3447481'], '54': ['Leopard-Shakira', 'Leopard-Mick', '0.2691906'], '55': ['Leopard-Shakira', 'Leopard-Keanu', '0.02002288'], '56': ['Leopard-Lewa', 'Leopard-Lewa', '0.77305084'], '57': ['Leopard-Mick', 'Leopard-Mick', '0.018188413'], '58': ['Leopard-Tony', 'Leopard-Wahoo', '0.23865905'], '59': ['Leopard-Timbila', 'Leopard-Ombeli', '0.033984266'], '60': ['Leopard-Timbila', 'Leopard-Tony', '0.17483468'], '61': ['Leopard-Wahoo', 'Leopard-Mick', '0.20921896'], '62': ['Leopard-Wahoo', 'Leopard-Lewa', '0.9732933'], '63': ['Leopard-Ombeli', 'Leopard-Ombeli', '0.3670207'], '64': ['Leopard-Ombeli', 'Leopard-Shakira', '0.01878126'], '65': ['Lowland Tapir-Chuva F', 'Lowland Tapir-Chuvisco M', '0.36689118'], '66': ['Lowland Tapir-Chuvisco M', 'Lowland Tapir-Chuvisco M', '0.38136098'], '67': ['Lowland Tapir-Edinha F', 'Lowland Tapir-Feminha F', '0.1411816'], '68': ['Lowland Tapir-Feminha F', 'Lowland Tapir-Edinha F', '0.17122494'], '69': ['Lowland Tapir-Feminha F', 'Lowland Tapir-Riscado M', '0.3736795'], '70': ['Lowland Tapir-Pistolinha M', 'Lowland Tapir-Chuva F', '0.11767616'], '71': ['Lowland Tapir-Riscado M', 'Lowland Tapir-Pistolinha M', '0.047722176'], '72': ['Lowland Tapir-Riscado M', 'Lowland Tapir-Sorocaba 2', '0.036196947'], '73': ['Lowland Tapir-Sorocaba', 'Lowland Tapir-Sorocaba 2', '0.12280552'], '74': ['Lowland Tapir-Sorocaba', 'Lowland Tapir-Riscado M', '0.022205234'], '75': ['Lowland Tapir-Sorocaba 2', 'Lowland Tapir-Feminha F', '0.15691665'], '76': ['Lowland Tapir-Sorocaba 5', 'Lowland Tapir-Sorocaba', '0.1273046'], '77': ['Puma-F-Archback', 'Puma-M-Pops', '0.26911953'], '78': ['Puma-F-Cassie', 'Puma-F-Lip', '0.21911356'], '79': ['Puma-F-Lip', 'Puma-F-Majanna', '0.13774154'], '80': ['Puma-F-Spots', 'Puma-M-Skit', '0.1455407'], '81': ['Puma-M-Darby', 'Puma-M-Pops', '0.010045819'], '82': ['Puma-M-Juvboy', 'Puma-F-Lip', '0.027777046'], '83': ['Puma-M-Juvboy', 'Puma-M-Phoenix', '0.15293047'], '84': ['Puma-M-Juvboy', 'Puma-M-Pops', '0.30215472'], '85': ['Puma-M-Juvboy', 'Puma-F-Majanna', '0.26125008'], '86': ['Puma-M-Oldex', 'Puma-M-Juvboy', '0.06967069'], '87': ['Puma-M-Oldex', 'Puma-M-Skit', '0.15179786'], '88': ['Puma-M-Phoenix', 'Puma-M-Phoenix', '0.029924575'], '89': ['Puma-M-Pops', 'Puma-M-Phoenix', '0.14632495'], '90': ['Puma-M-Pops', 'Puma-M-Skit', '0.14665192'], '91': ['Puma-M-Pops', 'Puma-F-Spots', '0.23037761'], '92': ['Puma-M-Pops', 'Puma-F-Archback', '0.16558717'], '93': ['Puma-M-Pops', 'Puma-M-Skit', '0.23872086'], '94': ['Puma-M-Pops', 'Puma-M-Oldex', '0.15572608'], '95': ['Puma-M-Pops', 'Puma-F-Majanna', '0.10749846'], '96': ['Puma-M-Pops', 'Puma-F-Archback', '0.16729294'], '97': ['Puma-M-Pops', 'Puma-F-Archback', '0.10599053'], '98': ['Puma-M-Pops', 'Puma-F-Archback', '0.37703657'], '99': ['Puma-M-Skit', 'Puma-M-Oldex', '0.019408088'], '100': ['Puma-M-Taz', 'Puma-M-Oldex', '0.09289292'], '101': ['Puma-M-Taz', 'Puma-M-Skit', '0.11220469'], '102': ['Puma-F-Tawny', 'Puma-M-Oldex', '0.010550305'], '103': ['Puma-F-Majanna', 'Puma-M-Taz', '0.014437192'], '104': ['White Rhino-Kal Cs 6JunKML2', 'White Rhino-Kal Cs 6JunKML2', '0.23851544'], '105': ['White Rhino-Kal Cs 9JunKML3', 'White Rhino-Kal Cs 6JunKML2', '0.19497876'], '106': ['White Rhino-Kal Cs 9JunKML3', 'White Rhino-Kal Cs 9JunKML3', '0.43153676'], '107': ['White Rhino-Kalakwa Cs5', 'White Rhino-Kalakwa Cs7', '0.008806495'], '108': ['White Rhino-Kalakwa Cs5', 'White Rhino-Kal Cs 6JunKML2', '0.16113816'], '109': ['White Rhino-Kalakwa Cs6', 'White Rhino-Kal Cs 6JunKML2', '0.04242063'], '110': ['White Rhino-Kalakwa Cs6', 'White Rhino-Kalakwa Cs10', '0.17146969'], '111': ['White Rhino-Kalakwa Cs7', 'White Rhino-Kalakwa Cs7', '1.0792994'], '112': ['White Rhino-Kalakwa Cs10', 'White Rhino-Kalakwa Cs6', '0.1276811'], '113': ['White Rhino-Kalakwa Cs10', 'White Rhino-Kalakwa Cs7', '0.29934293'], '114': ['White Rhino-Kalakwa Cs15', 'White Rhino-Kalakwa Cs15', '0.1464836'], '115': ['White Rhino-Kalakwa Cs15', 'White Rhino-Kalakwa Cs5', '0.18201602'], '116': ['White Rhino-Kalakwa Cs17', 'White Rhino-Kalakwa Cs17', '0.049518596'], '117': ['White Rhino-Kalakwa Cs17', 'White Rhino-Kalakwa Cs5', '0.71722823'], '118': ['Black Rhino-Kal Db Himb', 'Black Rhino-Kal Db Himb', '0.048028275'], '119': ['Black Rhino-Kal Db Jav', 'Black Rhino-Kuz Db Col', '0.24025948'], '120': ['Black Rhino-Kal Db Jav', 'Black Rhino-Kuz Db Col', '0.030562732'], '121': ['Black Rhino-Kal Db Kuz', 'Black Rhino-Kuz Db Col', '0.04677956'], '122': ['Black Rhino-Kal Db M1', 'Black Rhino-Kuz Db Ken', '0.73433256'], '123': ['Black Rhino-Kal Db M1', 'Black Rhino-Kal Db M1', '0.059791412'], '124': ['Black Rhino-Kal Db M2', 'Black Rhino-Kal Db M1', '0.1371456'], '125': ['Black Rhino-Kal Db M2', 'Black Rhino-Kal Db M1', '0.09226123'], '126': ['Black Rhino-Kuz Db Col', 'Black Rhino-Kuz Db Hel', '0.39537254'], '127': ['Black Rhino-Kuz Db Col', 'Black Rhino-Kuz Db Hel', '0.009371113'], '128': ['Black Rhino-Kuz Db Hec', 'Black Rhino-Kal Db Jav', '0.053047094'], '129': ['Black Rhino-Kuz Db Hec', 'Black Rhino-Kuz Db Col', '0.3412417'], '130': ['Black Rhino-Kuz Db Hel', 'Black Rhino-Kuz Db Hec', '1.0404923'], '131': ['Black Rhino-Kuz Db Hel', 'Black Rhino-Kuz Db Col', '0.4144354'], '132': ['Black Rhino-Kuz Db Ken', 'Black Rhino-Kal Db M2', '0.18399036'], '133': ['Black Rhino-Kuz Db Ken', 'Black Rhino-Kuz Db Hel', '0.03735394'], '134': ['African lion-Mogli', 'African lion-Elsa', '0.07142687'], '135': ['African lion-Mogli', 'African lion-Mapivu', '0.4268669'], '136': ['African lion-Inca', 'African lion-Bijan', '0.049336147'], '137': ['African lion-Inca', 'African lion-Bijan', '0.05946173'], '138': ['African lion-Ceasar', 'African lion-Jan', '0.004237823'], '139': ['African lion-Ceasar', 'African lion-Bijan', '0.07816058'], '140': ['African lion-Ceasar', 'African lion-Jan', '0.020849787'], '141': ['African lion-Ceasar', 'African lion-Elangeny', '0.020981036'], '142': ['African lion-Jan', 'African lion-Jamu', '0.600444'], '143': ['African lion-Jan', 'African lion-Mogli', '0.1159382'], '144': ['African lion-Jan', 'African lion-Mogli', '0.54929715'], '145': ['African lion-Jan', 'African lion-Ceasar', '0.24453506'], '146': ['African lion-Jamu', 'African lion-Ceasar', '0.14899315'], '147': ['African lion-Jamu', 'African lion-Jamu', '0.97694963'], '148': ['African lion-Maro', 'African lion-Inca', '0.22441526'], '149': ['African lion-Maro', 'African lion-Inca', '0.05726934'], '150': ['African lion-Elsa', 'African lion-Jamu', '0.03688925'], '151': ['African lion-Elsa', 'African lion-Mogli', '0.06554171'], '152': ['African lion-Mapivu', 'African lion-Ceasar', '0.39981046'], '153': ['African lion-Mapivu', 'African lion-Maro', '0.09744669'], '154': ['African lion-Bijan', 'African lion-Maro', '0.021870403'], '155': ['African lion-Bijan', 'African lion-Inca', '0.19332658'], '156': ['African lion-Bijan', 'African lion-Mapivu', '0.07986751'], '157': ['African lion-Bijan', 'African lion-Ceasar', '0.044445544'], '158': ['African lion-Elangeny', 'African lion-Maro', '0.412951'], '159': ['African lion-Elangeny', 'African lion-Inca', '0.1000069'], '160': ['African lion-Elangeny', 'African lion-Inca', '0.5492623'], '161': ['African lion-Elangeny', 'African lion-Elangeny', '0.28942102'], '162': ['African elephant-Chikenya', 'African elephant-Chikenya', '0.06572834'], '163': ['African elephant-Chikenya', 'African elephant-Lorato', '0.2016486'], '164': ['African elephant-Paseka', 'African elephant-Mashudu', '0.258154'], '165': ['African elephant-Thandi', 'African elephant-Sene', '0.34792414'], '166': ['African elephant-Thandi', 'African elephant-Lorato', '0.09126206'], '167': ['African elephant-Thandi', 'African elephant-Thandi', '0.6479549'], '168': ['African elephant-Thandi', 'African elephant-Chikenya', '0.30815977'], '169': ['African elephant-Thandi', 'African elephant-Chikenya', '0.14338516'], '170': ['African elephant-Lorato', 'African elephant-Abu', '0.07417773'], '171': ['African elephant-Lorato', 'African elephant-Thandi', '0.036195405'], '172': ['African elephant-Lorato', 'African elephant-Thato', '0.08028771'], '173': ['African elephant-Sukeri', 'African elephant-Sukeri', '0.50868326'], '174': ['African elephant-Sukeri', 'African elephant-Abu', '0.6050804'], '175': ['African elephant-Sukeri', 'African elephant-Paseka', '0.33801416'], '176': ['African elephant-Thato', 'African elephant-Sukeri', '0.015766826'], '177': ['African elephant-Thato', 'African elephant-Paseka', '0.1550908'], '178': ['African elephant-Mashudu', 'African elephant-Abu', '0.33626306'], '179': ['African elephant-Mashudu', 'African elephant-Thato', '0.25706533'], '180': ['African elephant-Sene', 'African elephant-Chikenya', '0.25701964'], '181': ['African elephant-Abu', 'African elephant-Paseka', '0.04209629'], '182': ['African elephant-Abu', 'African elephant-Thato', '0.02931794'], '183': ['African elephant-Abu', 'African elephant-Chikenya', '0.13800554'], '184': ['African elephant-Abu', 'African elephant-Thato', '0.21142201'], '185': ['Bongo-Rehema', 'Bongo-Rehema', '0.46257216'], '186': ['Bongo-Rehema', 'Bongo-Rehema', '0.25986287'], '187': ['Bongo-Rehema', 'Bongo-Rehema', '0.17747979'], '188': ['Bongo-Rehema', 'Bongo-Rehema', '0.10740933'], '189': ['Bongo-Bambi', 'Bongo-Lucy', '0.2888128'], '190': ['Bongo-Bambi', 'Bongo-Amani', '0.091322005'], '191': ['Bongo-Amani', 'Bongo-Nengese', '0.4111528'], '192': ['Bongo-Lucy', 'Bongo-Bambi', '0.08497388'], '193': ['Bongo-Lucy', 'Bongo-Lucy', '0.033937767'], '194': ['Bongo-Nolano', 'Bongo-Nolano', '0.062078606'], '195': ['Bongo-Nolano', 'Bongo-Nolano', '0.097754285'], '196': ['Bongo-Nolano', 'Bongo-Bambi', '0.1709944'], '197': ['Bongo-Nengese', 'Bongo-Nengese', '0.034126457'], '198': ['Bongo-Nengese', 'Bongo-Bambi', '0.16414629'], '199': ['Bongo-Malaika', 'Bongo-Bambi', '0.1524869'], '200': ['Bongo-Malaika', 'Bongo-Bambi', '0.18354018'], '201': ['Bongo-Malaika', 'Bongo-Bambi', '0.47691554'], '202': ['Bongo-Kalama', 'Bongo-Malaika', '0.05421006'], '203': ['Bongo-Kalama', 'Bongo-Kalama', '0.04668729']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TySBexXQhERg",
        "colab_type": "text"
      },
      "source": [
        "Finally, the accuracy is measured by comparing the actual individual classes with the predicted individual classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YjEeJvgDEED",
        "colab_type": "code",
        "outputId": "92f81296-7db9-4241-a59d-24cd510d80bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "for img in results_dict.keys():\n",
        "  total += 1\n",
        "  actual = results_dict[img][0]\n",
        "  predicted = results_dict[img][1]\n",
        "  if actual == predicted:\n",
        "    correct += 1\n",
        "\n",
        "print(\"Total Images = \", total)\n",
        "print(\"Number of Correct Predictions = \", correct)\n",
        "print(\"Accuracy = \", correct/total)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Images =  204\n",
            "Number of Correct Predictions =  36\n",
            "Accuracy =  0.17647058823529413\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}